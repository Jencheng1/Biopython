{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ACCESS BIOINFORMATICS DATABASES WITH BIO-PYTHON"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. [NCBI](#1.-NCBI)<br>\n",
    "    1.1. [Nucleotide BLAST](#1.1.-Nucleotide-BLAST)<br>\n",
    "    1.2. [Protein BLAST](#1.2.-Protein-BLAST)\n",
    "    \n",
    "2. [ENTREZ](#2.-ENTREZ)<br>\n",
    "    2.1. [PUBMED](#2.1.-PUBMED)<br>\n",
    "    2.2. [Nucleotide](#2.2.-Nucleotide)\n",
    "    \n",
    "3. [PDB](#3.-PDB)\n",
    "\n",
    "4. [EXPASY](#4.-EXPASY)<br>\n",
    "    4.1. [PROSITE](#4.1.-PROSITE)<br>\n",
    "    4.2. [ScanProsite](#4.2.-ScanProsite)\n",
    "    \n",
    "5. [KEGG](#5.-KEGG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. NCBI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Bio.Blast import NCBIWWW\n",
    "from Bio import SeqIO, SearchIO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on module Bio.Blast.NCBIWWW in Bio.Blast:\n",
      "\n",
      "NAME\n",
      "    Bio.Blast.NCBIWWW - Code to invoke the NCBI BLAST server over the internet.\n",
      "\n",
      "DESCRIPTION\n",
      "    This module provides code to work with the WWW version of BLAST\n",
      "    provided by the NCBI. https://blast.ncbi.nlm.nih.gov/\n",
      "    \n",
      "    Variables:\n",
      "    \n",
      "        - email        Set the Blast email parameter (default is None).\n",
      "        - tool         Set the Blast tool parameter (default is ``biopython``).\n",
      "\n",
      "FUNCTIONS\n",
      "    qblast(program, database, sequence, url_base='https://blast.ncbi.nlm.nih.gov/Blast.cgi', auto_format=None, composition_based_statistics=None, db_genetic_code=None, endpoints=None, entrez_query='(none)', expect=10.0, filter=None, gapcosts=None, genetic_code=None, hitlist_size=50, i_thresh=None, layout=None, lcase_mask=None, matrix_name=None, nucl_penalty=None, nucl_reward=None, other_advanced=None, perc_ident=None, phi_pattern=None, query_file=None, query_believe_defline=None, query_from=None, query_to=None, searchsp_eff=None, service=None, threshold=None, ungapped_alignment=None, word_size=None, short_query=None, alignments=500, alignment_view=None, descriptions=500, entrez_links_new_window=None, expect_low=None, expect_high=None, format_entrez_query=None, format_object=None, format_type='XML', ncbi_gi=None, results_file=None, show_overview=None, megablast=None, template_type=None, template_length=None, username='blast', password=None)\n",
      "        BLAST search using NCBI's QBLAST server or a cloud service provider.\n",
      "        \n",
      "        Supports all parameters of the old qblast API for Put and Get.\n",
      "        \n",
      "        Please note that NCBI uses the new Common URL API for BLAST searches\n",
      "        on the internet (http://ncbi.github.io/blast-cloud/dev/api.html). Thus,\n",
      "        some of the parameters used by this function are not (or are no longer)\n",
      "        officially supported by NCBI. Although they are still functioning, this\n",
      "        may change in the future.\n",
      "        \n",
      "        The Common URL API (http://ncbi.github.io/blast-cloud/dev/api.html) allows\n",
      "        doing BLAST searches on cloud servers. To use this feature, please set\n",
      "        ``url_base='http://host.my.cloud.service.provider.com/cgi-bin/blast.cgi'``\n",
      "        and ``format_object='Alignment'``. For more details, please see\n",
      "        https://blast.ncbi.nlm.nih.gov/Blast.cgi?PAGE_TYPE=BlastDocs&DOC_TYPE=CloudBlast\n",
      "        \n",
      "        Some useful parameters:\n",
      "        \n",
      "         - program        blastn, blastp, blastx, tblastn, or tblastx (lower case)\n",
      "         - database       Which database to search against (e.g. \"nr\").\n",
      "         - sequence       The sequence to search.\n",
      "         - ncbi_gi        TRUE/FALSE whether to give 'gi' identifier.\n",
      "         - descriptions   Number of descriptions to show.  Def 500.\n",
      "         - alignments     Number of alignments to show.  Def 500.\n",
      "         - expect         An expect value cutoff.  Def 10.0.\n",
      "         - matrix_name    Specify an alt. matrix (PAM30, PAM70, BLOSUM80, BLOSUM45).\n",
      "         - filter         \"none\" turns off filtering.  Default no filtering\n",
      "         - format_type    \"HTML\", \"Text\", \"ASN.1\", or \"XML\".  Def. \"XML\".\n",
      "         - entrez_query   Entrez query to limit Blast search\n",
      "         - hitlist_size   Number of hits to return. Default 50\n",
      "         - megablast      TRUE/FALSE whether to use MEga BLAST algorithm (blastn only)\n",
      "         - short_query    TRUE/FALSE whether to adjust the search parameters for a\n",
      "                          short query sequence. Note that this will override\n",
      "                          manually set parameters like word size and e value. Turns\n",
      "                          off when sequence length is > 30 residues. Default: None.\n",
      "         - service        plain, psi, phi, rpsblast, megablast (lower case)\n",
      "        \n",
      "        This function does no checking of the validity of the parameters\n",
      "        and passes the values to the server as is.  More help is available at:\n",
      "        https://ncbi.github.io/blast-cloud/dev/api.html\n",
      "\n",
      "DATA\n",
      "    NCBI_BLAST_URL = 'https://blast.ncbi.nlm.nih.gov/Blast.cgi'\n",
      "    email = None\n",
      "    tool = 'biopython'\n",
      "\n",
      "FILE\n",
      "    /opt/conda/lib/python3.10/site-packages/Bio/Blast/NCBIWWW.py\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#help(NCBIWWW)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1. Nucleotide BLAST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "notebook.ipynb\tnuc_seq.fasta  prot_seq.fasta\r\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "774"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nuc_record = SeqIO.read(\"nuc_seq.fasta\", format = \"fasta\")\n",
    "len(nuc_record)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'MT598137.1 Severe acute respiratory syndrome coronavirus 2 isolate SARS-CoV-2/human/IRN/PN-2142-S/2020 surface glycoprotein (S) gene, partial cds'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nuc_record.description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Seq('ATCGCTCCAGGGCAAACTGGAAAGATTGCTGATTATAATTATAAATTACCAGAT...GGT')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nuc_record.seq\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_handle = NCBIWWW.qblast(\"blastn\", \"nt\", nuc_record.seq)\n",
    "blast_result = SearchIO.read(result_handle, \"blast-xml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Program: blastn (2.16.0+)\n",
      "  Query: No (774)\n",
      "         definition line\n",
      " Target: core_nt\n",
      "   Hits: ----  -----  ----------------------------------------------------------\n",
      "            #  # HSP  ID + description\n",
      "         ----  -----  ----------------------------------------------------------\n",
      "            0      1  gi|2633241341|emb|OY967334.1|  Severe acute respiratory...\n",
      "            1      1  gi|2521539964|emb|OX660655.1|  Severe acute respiratory...\n"
     ]
    }
   ],
   "source": [
    "print(blast_result[0:2])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequence ID: gi|2633241341|emb|OY967334.1|\n",
      "Sequence Description: Severe acute respiratory syndrome coronavirus 2 genome assembly, complete genome: monopartite\n",
      "E-value: 0.0\n"
     ]
    }
   ],
   "source": [
    "Seq = blast_result[0]\n",
    "print(f\"Sequence ID: {Seq.id}\")\n",
    "print(f\"Sequence Description: {Seq.description}\")\n",
    "\n",
    "details = Seq[0]\n",
    "print(f\"E-value: {details.evalue}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alignment:\n",
      "Alignment with 2 rows and 774 columns\n",
      "ATCGCTCCAGGGCAAACTGGAAAGATTGCTGATTATAATTATAA...GGT No\n",
      "ATCGCTCCAGGGCAAACTGGAAAGATTGCTGATTATAATTATAA...GGT gi|2633241341|emb|OY967334.1|\n"
     ]
    }
   ],
   "source": [
    "print(f\"alignment:\\n{details.aln}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2. Protein BLAST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "258"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prot_record = SeqIO.read(\"prot_seq.fasta\", format=\"fasta\")\n",
    "len(prot_record)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_handle = NCBIWWW.qblast(\"blastp\", \"pdb\", prot_record.seq)\n",
    "blast_result = SearchIO.read(result_handle, \"blast-xml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Program: blastp (2.16.0+)\n",
      "  Query: unnamed (258)\n",
      "         protein product\n",
      " Target: pdb\n",
      "   Hits: ----  -----  ----------------------------------------------------------\n",
      "            #  # HSP  ID + description\n",
      "         ----  -----  ----------------------------------------------------------\n",
      "            0      1  pdb|8ELJ|A  Chain A, Spike glycoprotein [Severe acute r...\n",
      "            1      1  pdb|7CAB|A  Chain A, Spike glycoprotein [Severe acute r...\n"
     ]
    }
   ],
   "source": [
    "print(blast_result[0:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequence ID: pdb|8ELJ|A\n",
      "Sequence Description: Chain A, Spike glycoprotein [Severe acute respiratory syndrome coronavirus 2]\n",
      "E-value: 0.0\n"
     ]
    }
   ],
   "source": [
    "Seq = blast_result [0]\n",
    "print(f\"Sequence ID: {Seq.id}\")\n",
    "print(f\"Sequence Description: {Seq.description}\")\n",
    "\n",
    "details = Seq[0]\n",
    "print(f\"E-value: {details.evalue}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alignment:\n",
      " Alignment with 2 rows and 258 columns\n",
      "IAPGQTGKIADYNYKLPDDFTGCVIAWNSNNLDSKVGGNYNYLY...PIG unnamed\n",
      "IAPGQTGKIADYNYKLPDDFTGCVIAWNSNNLDSKVGGNYNYLY...PIG pdb|8ELJ|A\n"
     ]
    }
   ],
   "source": [
    "print(f\"alignment:\\n {details.aln}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. ENTREZ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Bio import Entrez"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on package Bio.Entrez in Bio:\n",
      "\n",
      "NAME\n",
      "    Bio.Entrez - Provides code to access NCBI over the WWW.\n",
      "\n",
      "DESCRIPTION\n",
      "    The main Entrez web page is available at:\n",
      "    http://www.ncbi.nlm.nih.gov/Entrez/\n",
      "    \n",
      "    Entrez Programming Utilities web page is available at:\n",
      "    http://www.ncbi.nlm.nih.gov/books/NBK25501/\n",
      "    \n",
      "    This module provides a number of functions like ``efetch`` (short for\n",
      "    Entrez Fetch) which will return the data as a handle object. This is\n",
      "    a standad interface used in Python for reading data from a file, or\n",
      "    in this case a remote network connection, and provides methods like\n",
      "    ``.read()`` or offers iteration over the contents line by line. See\n",
      "    also \"What the heck is a handle?\" in the Biopython Tutorial and\n",
      "    Cookbook: http://biopython.org/DIST/docs/tutorial/Tutorial.html\n",
      "    http://biopython.org/DIST/docs/tutorial/Tutorial.pdf\n",
      "    The handle returned by these functions can be either in text mode or\n",
      "    in binary mode, depending on the data requested and the results\n",
      "    returned by NCBI Entrez. Typically, XML data will be in binary mode\n",
      "    while other data will be in text mode, as required by the downstream\n",
      "    parser to parse the data.\n",
      "    \n",
      "    Unlike a handle to a file on disk from the ``open(filename)`` function,\n",
      "    which has a ``.name`` attribute giving the filename, the handles from\n",
      "    ``Bio.Entrez`` all have a ``.url`` attribute instead giving the URL\n",
      "    used to connect to the NCBI Entrez API.\n",
      "    \n",
      "    The ``epost``, ``efetch``, and ``esummary`` tools take an \"id\" parameter\n",
      "    which corresponds to one or more database UIDs (or accession.version\n",
      "    identifiers in the case of sequence databases such as \"nuccore\" or\n",
      "    \"protein\"). The Python value of the \"id\" keyword passed to these functions\n",
      "    may be either a single ID as a string or integer or multiple IDs as an\n",
      "    iterable of strings/integers. You may also pass a single string containing\n",
      "    multiple IDs delimited by commas. The ``elink`` tool also accepts multiple\n",
      "    IDs but the argument is handled differently than the other three. See that\n",
      "    function's docstring for more information.\n",
      "    \n",
      "    All the functions that send requests to the NCBI Entrez API will\n",
      "    automatically respect the NCBI rate limit (of 3 requests per second\n",
      "    without an API key, or 10 requests per second with an API key) and\n",
      "    will automatically retry when encountering transient failures\n",
      "    (i.e. connection failures or HTTP 5XX codes). By default, Biopython\n",
      "    does a maximum of three tries before giving up, and sleeps for 15\n",
      "    seconds between tries. You can tweak these parameters by setting\n",
      "    ``Bio.Entrez.max_tries`` and ``Bio.Entrez.sleep_between_tries``.\n",
      "    \n",
      "    The Entrez module also provides an XML parser which takes a handle\n",
      "    as input.\n",
      "    \n",
      "    Variables:\n",
      "    \n",
      "        - email        Set the Entrez email parameter (default is not set).\n",
      "        - tool         Set the Entrez tool parameter (default is ``biopython``).\n",
      "        - api_key      Personal API key from NCBI. If not set, only 3 queries per\n",
      "          second are allowed. 10 queries per seconds otherwise with a\n",
      "          valid API key.\n",
      "        - max_tries    Configures how many times failed requests will be\n",
      "          automatically retried on error (default is 3).\n",
      "        - sleep_between_tries   The delay, in seconds, before retrying a request on\n",
      "          error (default is 15).\n",
      "    \n",
      "    Functions:\n",
      "    \n",
      "        - efetch       Retrieves records in the requested format from a list of one or\n",
      "          more primary IDs or from the user's environment\n",
      "        - epost        Posts a file containing a list of primary IDs for future use in\n",
      "          the user's environment to use with subsequent search strategies\n",
      "        - esearch      Searches and retrieves primary IDs (for use in EFetch, ELink,\n",
      "          and ESummary) and term translations and optionally retains\n",
      "          results for future use in the user's environment.\n",
      "        - elink        Checks for the existence of an external or Related Articles link\n",
      "          from a list of one or more primary IDs.  Retrieves primary IDs\n",
      "          and relevancy scores for links to Entrez databases or Related\n",
      "          Articles;  creates a hyperlink to the primary LinkOut provider\n",
      "          for a specific ID and database, or lists LinkOut URLs\n",
      "          and Attributes for multiple IDs.\n",
      "        - einfo        Provides field index term counts, last update, and available\n",
      "          links for each database.\n",
      "        - esummary     Retrieves document summaries from a list of primary IDs or from\n",
      "          the user's environment.\n",
      "        - egquery      Provides Entrez database counts in XML for a single search\n",
      "          using Global Query.\n",
      "        - espell       Retrieves spelling suggestions.\n",
      "        - ecitmatch    Retrieves PubMed IDs (PMIDs) that correspond to a set of\n",
      "          input citation strings.\n",
      "    \n",
      "        - read         Parses the XML results returned by any of the above functions.\n",
      "          Alternatively, the XML data can be read from a file opened in binary mode.\n",
      "          Typical usage is:\n",
      "    \n",
      "              >>> from Bio import Entrez\n",
      "              >>> Entrez.email = \"Your.Name.Here@example.org\"\n",
      "              >>> handle = Entrez.einfo() # or esearch, efetch, ...\n",
      "              >>> record = Entrez.read(handle)\n",
      "              >>> handle.close()\n",
      "    \n",
      "           where record is now a Python dictionary or list.\n",
      "    \n",
      "        - parse        Parses the XML results returned by those of the above functions\n",
      "          which can return multiple records - such as efetch, esummary\n",
      "          and elink. Typical usage is:\n",
      "    \n",
      "              >>> handle = Entrez.esummary(db=\"pubmed\", id=\"19304878,14630660\", retmode=\"xml\")\n",
      "              >>> records = Entrez.parse(handle)\n",
      "              >>> for record in records:\n",
      "              ...     # each record is a Python dictionary or list.\n",
      "              ...     print(record['Title'])\n",
      "              Biopython: freely available Python tools for computational molecular biology and bioinformatics.\n",
      "              PDB file parser and structure class implemented in Python.\n",
      "              >>> handle.close()\n",
      "    \n",
      "          This function is appropriate only if the XML file contains\n",
      "          multiple records, and is particular useful for large files.\n",
      "    \n",
      "        - _open        Internally used function.\n",
      "\n",
      "PACKAGE CONTENTS\n",
      "    Parser\n",
      "\n",
      "FUNCTIONS\n",
      "    ecitmatch(**keywds)\n",
      "        Retrieve PMIDs for input citation strings, returned as a handle.\n",
      "        \n",
      "        ECitMatch retrieves PubMed IDs (PMIDs) that correspond to a set of input\n",
      "        citation strings.\n",
      "        \n",
      "        See the online documentation for an explanation of the parameters:\n",
      "        http://www.ncbi.nlm.nih.gov/books/NBK25499/#chapter4.ECitMatch\n",
      "        \n",
      "        Short example:\n",
      "        \n",
      "        >>> from Bio import Entrez\n",
      "        >>> Entrez.email = \"Your.Name.Here@example.org\"\n",
      "        >>> citation_1 = {\"journal_title\": \"proc natl acad sci u s a\",\n",
      "        ...               \"year\": \"1991\", \"volume\": \"88\", \"first_page\": \"3248\",\n",
      "        ...               \"author_name\": \"mann bj\", \"key\": \"citation_1\"}\n",
      "        >>> handle = Entrez.ecitmatch(db=\"pubmed\", bdata=[citation_1])\n",
      "        >>> print(handle.read().strip().split(\"|\"))\n",
      "        ['proc natl acad sci u s a', '1991', '88', '3248', 'mann bj', 'citation_1', '2014248']\n",
      "        >>> handle.close()\n",
      "        \n",
      "        :returns: Handle to the results, by default in plain text.\n",
      "        :raises urllib.error.URLError: If there's a network error.\n",
      "    \n",
      "    efetch(db, **keywords)\n",
      "        Fetch Entrez results which are returned as a handle.\n",
      "        \n",
      "        EFetch retrieves records in the requested format from a list or set of one or\n",
      "        more UIs or from user's environment.\n",
      "        \n",
      "        See the online documentation for an explanation of the parameters:\n",
      "        http://www.ncbi.nlm.nih.gov/books/NBK25499/#chapter4.EFetch\n",
      "        \n",
      "        Short example:\n",
      "        \n",
      "        >>> from Bio import Entrez\n",
      "        >>> Entrez.email = \"Your.Name.Here@example.org\"\n",
      "        >>> handle = Entrez.efetch(db=\"nucleotide\", id=\"AY851612\", rettype=\"gb\", retmode=\"text\")\n",
      "        >>> print(handle.readline().strip())\n",
      "        LOCUS       AY851612                 892 bp    DNA     linear   PLN 10-APR-2007\n",
      "        >>> handle.close()\n",
      "        \n",
      "        This will automatically use an HTTP POST rather than HTTP GET if there\n",
      "        are over 200 identifiers as recommended by the NCBI.\n",
      "        \n",
      "        **Warning:** The NCBI changed the default retmode in Feb 2012, so many\n",
      "        databases which previously returned text output now give XML.\n",
      "        \n",
      "        :returns: Handle to the results.\n",
      "        :raises urllib.error.URLError: If there's a network error.\n",
      "    \n",
      "    egquery(**keywds)\n",
      "        Provide Entrez database counts for a global search (DEPRECATED).\n",
      "        \n",
      "        EGQuery provided Entrez database counts in XML for a single search\n",
      "        using Global Query. However, the NCBI are no longer maintaining this\n",
      "        function and suggest using esearch on each database of interest.\n",
      "        \n",
      "        See the online documentation for an explanation of the parameters:\n",
      "        http://www.ncbi.nlm.nih.gov/books/NBK25499/#chapter4.EGQuery\n",
      "        \n",
      "        This quick example based on a longer version from the Biopython\n",
      "        Tutorial just checks there are over 60 matches for 'Biopython'\n",
      "        in PubMedCentral:\n",
      "        \n",
      "        >>> from Bio import Entrez\n",
      "        >>> Entrez.email = \"Your.Name.Here@example.org\"\n",
      "        >>> handle = Entrez.egquery(term=\"biopython\")  # doctest: +SKIP\n",
      "        >>> record = Entrez.read(handle)  # doctest: +SKIP\n",
      "        >>> handle.close()  # doctest: +SKIP\n",
      "        >>> for row in record[\"eGQueryResult\"]:  # doctest: +SKIP\n",
      "        ...     if \"pmc\" in row[\"DbName\"]:  # doctest: +SKIP\n",
      "        ...         print(int(row[\"Count\"]) > 60)  # doctest: +SKIP\n",
      "        True\n",
      "        \n",
      "        :returns: Handle to the results, by default in XML format.\n",
      "        :raises urllib.error.URLError: If there's a network error.\n",
      "    \n",
      "    einfo(**keywds)\n",
      "        Return a summary of the Entrez databases as a results handle.\n",
      "        \n",
      "        EInfo provides field names, index term counts, last update, and\n",
      "        available links for each Entrez database.\n",
      "        \n",
      "        See the online documentation for an explanation of the parameters:\n",
      "        http://www.ncbi.nlm.nih.gov/books/NBK25499/#chapter4.EInfo\n",
      "        \n",
      "        Short example:\n",
      "        \n",
      "        >>> from Bio import Entrez\n",
      "        >>> Entrez.email = \"Your.Name.Here@example.org\"\n",
      "        >>> record = Entrez.read(Entrez.einfo())\n",
      "        >>> 'pubmed' in record['DbList']\n",
      "        True\n",
      "        \n",
      "        :returns: Handle to the results, by default in XML format.\n",
      "        :raises urllib.error.URLError: If there's a network error.\n",
      "    \n",
      "    elink(**keywds)\n",
      "        Check for linked external articles and return a handle.\n",
      "        \n",
      "        ELink checks for the existence of an external or Related Articles link\n",
      "        from a list of one or more primary IDs;  retrieves IDs and relevancy\n",
      "        scores for links to Entrez databases or Related Articles; creates a\n",
      "        hyperlink to the primary LinkOut provider for a specific ID and\n",
      "        database, or lists LinkOut URLs and attributes for multiple IDs.\n",
      "        \n",
      "        See the online documentation for an explanation of the parameters:\n",
      "        http://www.ncbi.nlm.nih.gov/books/NBK25499/#chapter4.ELink\n",
      "        \n",
      "        Note that ELink treats the \"id\" parameter differently than the other\n",
      "        tools when multiple values are given. You should generally pass multiple\n",
      "        UIDs as a list of strings or integers. This will provide a \"one-to-one\"\n",
      "        mapping from source database UIDs to destination database UIDs in the\n",
      "        result. If multiple source UIDs are passed as a single comma-delimited\n",
      "        string all destination UIDs will be mixed together in the result.\n",
      "        \n",
      "        This example finds articles related to the Biopython application\n",
      "        note's entry in the PubMed database:\n",
      "        \n",
      "        >>> from Bio import Entrez\n",
      "        >>> Entrez.email = \"Your.Name.Here@example.org\"\n",
      "        >>> pmid = \"19304878\"\n",
      "        >>> handle = Entrez.elink(dbfrom=\"pubmed\", id=pmid, linkname=\"pubmed_pubmed\")\n",
      "        >>> record = Entrez.read(handle)\n",
      "        >>> handle.close()\n",
      "        >>> print(record[0][\"LinkSetDb\"][0][\"LinkName\"])\n",
      "        pubmed_pubmed\n",
      "        >>> linked = [link[\"Id\"] for link in record[0][\"LinkSetDb\"][0][\"Link\"]]\n",
      "        >>> \"14630660\" in linked\n",
      "        True\n",
      "        \n",
      "        This is explained in much more detail in the Biopython Tutorial.\n",
      "        \n",
      "        :returns: Handle to the results, by default in XML format.\n",
      "        :raises urllib.error.URLError: If there's a network error.\n",
      "    \n",
      "    epost(db, **keywds)\n",
      "        Post a file of identifiers for future use.\n",
      "        \n",
      "        Posts a file containing a list of UIs for future use in the user's\n",
      "        environment to use with subsequent search strategies.\n",
      "        \n",
      "        See the online documentation for an explanation of the parameters:\n",
      "        http://www.ncbi.nlm.nih.gov/books/NBK25499/#chapter4.EPost\n",
      "        \n",
      "        :returns: Handle to the results.\n",
      "        :raises urllib.error.URLError: If there's a network error.\n",
      "    \n",
      "    esearch(db, term, **keywds)\n",
      "        Run an Entrez search and return a handle to the results.\n",
      "        \n",
      "        ESearch searches and retrieves primary IDs (for use in EFetch, ELink\n",
      "        and ESummary) and term translations, and optionally retains results\n",
      "        for future use in the user's environment.\n",
      "        \n",
      "        See the online documentation for an explanation of the parameters:\n",
      "        http://www.ncbi.nlm.nih.gov/books/NBK25499/#chapter4.ESearch\n",
      "        \n",
      "        Short example:\n",
      "        \n",
      "        >>> from Bio import Entrez\n",
      "        >>> Entrez.email = \"Your.Name.Here@example.org\"\n",
      "        >>> handle = Entrez.esearch(\n",
      "        ...     db=\"nucleotide\", retmax=10, idtype=\"acc\",\n",
      "        ...     term=\"opuntia[ORGN] accD 2007[Publication Date]\"\n",
      "        ... )\n",
      "        ...\n",
      "        >>> record = Entrez.read(handle)\n",
      "        >>> handle.close()\n",
      "        >>> int(record[\"Count\"]) >= 2\n",
      "        True\n",
      "        >>> \"EF590893.1\" in record[\"IdList\"]\n",
      "        True\n",
      "        >>> \"EF590892.1\" in record[\"IdList\"]\n",
      "        True\n",
      "        \n",
      "        :returns: Handle to the results, which are always in XML format.\n",
      "        :raises urllib.error.URLError: If there's a network error.\n",
      "    \n",
      "    espell(**keywds)\n",
      "        Retrieve spelling suggestions as a results handle.\n",
      "        \n",
      "        ESpell retrieves spelling suggestions, if available.\n",
      "        \n",
      "        See the online documentation for an explanation of the parameters:\n",
      "        http://www.ncbi.nlm.nih.gov/books/NBK25499/#chapter4.ESpell\n",
      "        \n",
      "        Short example:\n",
      "        \n",
      "        >>> from Bio import Entrez\n",
      "        >>> Entrez.email = \"Your.Name.Here@example.org\"\n",
      "        >>> record = Entrez.read(Entrez.espell(term=\"biopythooon\"))\n",
      "        >>> print(record[\"Query\"])\n",
      "        biopythooon\n",
      "        >>> print(record[\"CorrectedQuery\"])\n",
      "        biopython\n",
      "        \n",
      "        :returns: Handle to the results, by default in XML format.\n",
      "        :raises urllib.error.URLError: If there's a network error.\n",
      "    \n",
      "    esummary(**keywds)\n",
      "        Retrieve document summaries as a results handle.\n",
      "        \n",
      "        ESummary retrieves document summaries from a list of primary IDs or\n",
      "        from the user's environment.\n",
      "        \n",
      "        See the online documentation for an explanation of the parameters:\n",
      "        http://www.ncbi.nlm.nih.gov/books/NBK25499/#chapter4.ESummary\n",
      "        \n",
      "        This example discovers more about entry 19923 in the structure\n",
      "        database:\n",
      "        \n",
      "        >>> from Bio import Entrez\n",
      "        >>> Entrez.email = \"Your.Name.Here@example.org\"\n",
      "        >>> handle = Entrez.esummary(db=\"structure\", id=\"19923\")\n",
      "        >>> record = Entrez.read(handle)\n",
      "        >>> handle.close()\n",
      "        >>> print(record[0][\"Id\"])\n",
      "        19923\n",
      "        >>> print(record[0][\"PdbDescr\"])\n",
      "        CRYSTAL STRUCTURE OF E. COLI ACONITASE B\n",
      "        \n",
      "        \n",
      "        :returns: Handle to the results, by default in XML format.\n",
      "        :raises urllib.error.URLError: If there's a network error.\n",
      "    \n",
      "    parse(source, validate=True, escape=False, ignore_errors=False)\n",
      "        Parse an XML file from the NCBI Entrez Utilities into python objects.\n",
      "        \n",
      "        This function parses an XML file created by NCBI's Entrez Utilities,\n",
      "        returning a multilevel data structure of Python lists and dictionaries.\n",
      "        This function is suitable for XML files that (in Python) can be represented\n",
      "        as a list of individual records. Whereas 'read' reads the complete file\n",
      "        and returns a single Python list, 'parse' is a generator function that\n",
      "        returns the records one by one. This function is therefore particularly\n",
      "        useful for parsing large files.\n",
      "        \n",
      "        Most XML files returned by NCBI's Entrez Utilities can be parsed by\n",
      "        this function, provided its DTD is available. Biopython includes the\n",
      "        DTDs for most commonly used Entrez Utilities.\n",
      "        \n",
      "        The argument ``source`` must be a file or file-like object opened in binary\n",
      "        mode, or a filename. The parser detects the encoding from the XML file, and\n",
      "        uses it to convert all text in the XML to the correct Unicode string. The\n",
      "        functions in Bio.Entrez to access NCBI Entrez will automatically return XML\n",
      "        data in binary mode. For files, use mode \"rb\" when opening the file, as in\n",
      "        \n",
      "            >>> from Bio import Entrez\n",
      "            >>> path = \"Entrez/pubmed1.xml\"\n",
      "            >>> stream = open(path, \"rb\")  # opened in binary mode\n",
      "            >>> records = Entrez.parse(stream)\n",
      "            >>> for record in records:\n",
      "            ...     print(record['MedlineCitation']['Article']['Journal']['Title'])\n",
      "            ...\n",
      "            Social justice (San Francisco, Calif.)\n",
      "            Biochimica et biophysica acta\n",
      "            >>> stream.close()\n",
      "        \n",
      "        Alternatively, you can use the filename directly, as in\n",
      "        \n",
      "            >>> records = Entrez.parse(path)\n",
      "            >>> for record in records:\n",
      "            ...     print(record['MedlineCitation']['Article']['Journal']['Title'])\n",
      "            ...\n",
      "            Social justice (San Francisco, Calif.)\n",
      "            Biochimica et biophysica acta\n",
      "        \n",
      "        which is safer, as the file stream will automatically be closed after all\n",
      "        the records have been read, or if an error occurs.\n",
      "        \n",
      "        If validate is True (default), the parser will validate the XML file\n",
      "        against the DTD, and raise an error if the XML file contains tags that\n",
      "        are not represented in the DTD. If validate is False, the parser will\n",
      "        simply skip such tags.\n",
      "        \n",
      "        If escape is True, all characters that are not valid HTML are replaced\n",
      "        by HTML escape characters to guarantee that the returned strings are\n",
      "        valid HTML fragments. For example, a less-than sign (<) is replaced by\n",
      "        &lt;. If escape is False (default), the string is returned as is.\n",
      "        \n",
      "        If ignore_errors is False (default), any error messages in the XML file\n",
      "        will raise a RuntimeError. If ignore_errors is True, error messages will\n",
      "        be stored as ErrorElement items, without raising an exception.\n",
      "        \n",
      "        Whereas the data structure seems to consist of generic Python lists,\n",
      "        dictionaries, strings, and so on, each of these is actually a class\n",
      "        derived from the base type. This allows us to store the attributes\n",
      "        (if any) of each element in a dictionary my_element.attributes, and\n",
      "        the tag name in my_element.tag.\n",
      "    \n",
      "    read(source, validate=True, escape=False, ignore_errors=False)\n",
      "        Parse an XML file from the NCBI Entrez Utilities into python objects.\n",
      "        \n",
      "        This function parses an XML file created by NCBI's Entrez Utilities,\n",
      "        returning a multilevel data structure of Python lists and dictionaries.\n",
      "        Most XML files returned by NCBI's Entrez Utilities can be parsed by\n",
      "        this function, provided its DTD is available. Biopython includes the\n",
      "        DTDs for most commonly used Entrez Utilities.\n",
      "        \n",
      "        The argument ``source`` must be a file or file-like object opened in binary\n",
      "        mode, or a filename. The parser detects the encoding from the XML file, and\n",
      "        uses it to convert all text in the XML to the correct Unicode string. The\n",
      "        functions in Bio.Entrez to access NCBI Entrez will automatically return XML\n",
      "        data in binary mode. For files, use mode \"rb\" when opening the file, as in\n",
      "        \n",
      "            >>> from Bio import Entrez\n",
      "            >>> path = \"Entrez/esearch1.xml\"\n",
      "            >>> stream = open(path, \"rb\")  # opened in binary mode\n",
      "            >>> record = Entrez.read(stream)\n",
      "            >>> print(record['QueryTranslation'])\n",
      "            biopython[All Fields]\n",
      "            >>> stream.close()\n",
      "        \n",
      "        Alternatively, you can use the filename directly, as in\n",
      "        \n",
      "            >>> record = Entrez.read(path)\n",
      "            >>> print(record['QueryTranslation'])\n",
      "            biopython[All Fields]\n",
      "        \n",
      "        which is safer, as the file stream will automatically be closed after the\n",
      "        record has been read, or if an error occurs.\n",
      "        \n",
      "        If validate is True (default), the parser will validate the XML file\n",
      "        against the DTD, and raise an error if the XML file contains tags that\n",
      "        are not represented in the DTD. If validate is False, the parser will\n",
      "        simply skip such tags.\n",
      "        \n",
      "        If escape is True, all characters that are not valid HTML are replaced\n",
      "        by HTML escape characters to guarantee that the returned strings are\n",
      "        valid HTML fragments. For example, a less-than sign (<) is replaced by\n",
      "        &lt;. If escape is False (default), the string is returned as is.\n",
      "        \n",
      "        If ignore_errors is False (default), any error messages in the XML file\n",
      "        will raise a RuntimeError. If ignore_errors is True, error messages will\n",
      "        be stored as ErrorElement items, without raising an exception.\n",
      "        \n",
      "        Whereas the data structure seems to consist of generic Python lists,\n",
      "        dictionaries, strings, and so on, each of these is actually a class\n",
      "        derived from the base type. This allows us to store the attributes\n",
      "        (if any) of each element in a dictionary my_element.attributes, and\n",
      "        the tag name in my_element.tag.\n",
      "\n",
      "DATA\n",
      "    api_key = None\n",
      "    email = 'datacyclopes@gmail.com'\n",
      "    local_cache = None\n",
      "    max_tries = 3\n",
      "    sleep_between_tries = 15\n",
      "    tool = 'biopython'\n",
      "\n",
      "FILE\n",
      "    /opt/conda/lib/python3.10/site-packages/Bio/Entrez/__init__.py\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#help(Entrez)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "Entrez.email = \"datacyclopes@gmail.com\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['pubmed', 'protein', 'nuccore', 'ipg', 'nucleotide', 'structure', 'genome', 'annotinfo', 'assembly', 'bioproject', 'biosample', 'blastdbinfo', 'books', 'cdd', 'clinvar', 'gap', 'gapplus', 'grasp', 'dbvar', 'gene', 'gds', 'geoprofiles', 'medgen', 'mesh', 'nlmcatalog', 'omim', 'orgtrack', 'pmc', 'popset', 'proteinclusters', 'pcassay', 'protfam', 'pccompound', 'pcsubstance', 'seqannot', 'snp', 'sra', 'taxonomy', 'biocollections', 'gtr']"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "handle = Entrez.einfo()\n",
    "record = Entrez.read(handle)\n",
    "record[\"DbList\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1. PUBMED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'PubMed bibliographic record'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "handle = Entrez.einfo(db=\"pubmed\")\n",
    "record = Entrez.read(handle)\n",
    "record[\"DbInfo\"][\"Description\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'37859381'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "record[\"DbInfo\"][\"Count\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['38808697', '38650605', '38365590', '38235175', '37810457', '37668712', '36818783', '36245797', '36094101', '35497637', '35496474', '35402671', '34735950', '34484417', '34434786', '34189012', '33994075', '33902722', '33809815', '33242467']"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "handle = Entrez.esearch(db=\"pubmed\", term=\"biopython\")\n",
    "record = Entrez.read(handle)\n",
    "record[\"IdList\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Ullah S', 'Rahman W', 'Ullah F', 'Ullah A', 'Ahmad G', 'Ijaz M', 'Ullah H', 'Sharafmal DM'] The HABD: Home of All Biological Databases Empowering Biological Research With Cutting-Edge Database Systems. 2024 May Current protocols\n",
      "['Sulkowski A', 'Bouton C', 'Swanson C'] Syn-CpG-Spacer: A Panel web app for synonymous recoding of viral genomes with CpG dinucleotides. 2024 Apr 3 Journal of open source software\n"
     ]
    }
   ],
   "source": [
    "handle = Entrez.esummary(db=\"pubmed\", id= '38808697, 38650605')\n",
    "records = Entrez.parse(handle)\n",
    "\n",
    "\n",
    "for record in records:\n",
    "    #print(record)\n",
    "    print(record['AuthorList'], record['Title'], record['PubDate'], record['FullJournalName'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'<?xml version=\"1.0\" ?>\\n<!DOCTYPE PubmedArticleSet PUBLIC \"-//NLM//DTD PubMedArticle, 1st January 2024//EN\" \"https://dtd.nlm.nih.gov/ncbi/pubmed/out/pubmed_240101.dtd\">\\n<PubmedArticleSet>\\n<PubmedArticle><MedlineCitation Status=\"MEDLINE\" Owner=\"NLM\"><PMID Version=\"1\">19811691</PMID><DateCompleted><Year>2010</Year><Month>02</Month><Day>12</Day></DateCompleted><DateRevised><Year>2021</Year><Month>10</Month><Day>20</Day></DateRevised><Article PubModel=\"Electronic\"><Journal><ISSN IssnType=\"Electronic\">1471-2105</ISSN><JournalIssue CitedMedium=\"Internet\"><Volume>10 Suppl 11</Volume><Issue>Suppl 11</Issue><PubDate><Year>2009</Year><Month>Oct</Month><Day>08</Day></PubDate></JournalIssue><Title>BMC bioinformatics</Title><ISOAbbreviation>BMC Bioinformatics</ISOAbbreviation></Journal><ArticleTitle>Exploratory visual analysis of conserved domains on multiple sequence alignments.</ArticleTitle><Pagination><StartPage>S7</StartPage><MedlinePgn>S7</MedlinePgn></Pagination><ELocationID EIdType=\"doi\" ValidYN=\"Y\">10.1186/1471-2105-10-S11-S7</ELocationID><Abstract><AbstractText Label=\"BACKGROUND\" NlmCategory=\"BACKGROUND\">Multiple alignment of protein sequences can provide insight into sequence conservation across many species and thus allow identification of those sections of the sequence most critical to protein function. This insight can be augmented by joint display of conserved domains along the sequences. By fusing this metadata visually, biologists can analyze sequence conservation and functional motifs simultaneously and efficiently.</AbstractText><AbstractText Label=\"RESULTS\" NlmCategory=\"RESULTS\">We present MSAVis, a new approach combining luminance and hue for simultaneous visualization of conserved motifs and sequence alignment. Input for the algorithm is a multiple sequence alignment in a standard format. The NCBI Conserved Domain Database (CDD) is used for finding conserved domains along the alignment. The visualization quickly identifies conserved domains, and allows both macro (sequence-long) and micro (small amino-acid neighborhood) views.</AbstractText><AbstractText Label=\"CONCLUSION\" NlmCategory=\"CONCLUSIONS\">MSAVis utilizes two visual cues, luminance and hue, to facilitate at-a-glance summary of the conservation of a user-provided protein alignment while enabling multiple comparisons among functional domains. These visual cues are preattentive and separable so that the relationship between conservation strength and domain membership can be understood. The MSAVis software, written in Python and using BioPython and OpenGL, can be found at http://agbase.msstate.edu/tools/MSAVis.html.</AbstractText></Abstract><AuthorList CompleteYN=\"Y\"><Author ValidYN=\"Y\"><LastName>Jankun-Kelly</LastName><ForeName>T J</ForeName><Initials>TJ</Initials><AffiliationInfo><Affiliation>Institute for Digital Biology and Department of Computer Science and Engineering, Bagley College of Engineering, Mississippi State University, Mississippi, USA. tjk@acm.org</Affiliation></AffiliationInfo></Author><Author ValidYN=\"Y\"><LastName>Lindeman</LastName><ForeName>Andrew D</ForeName><Initials>AD</Initials></Author><Author ValidYN=\"Y\"><LastName>Bridges</LastName><ForeName>Susan M</ForeName><Initials>SM</Initials></Author></AuthorList><Language>eng</Language><PublicationTypeList><PublicationType UI=\"D016428\">Journal Article</PublicationType><PublicationType UI=\"D013486\">Research Support, U.S. Gov\\'t, Non-P.H.S.</PublicationType></PublicationTypeList><ArticleDate DateType=\"Electronic\"><Year>2009</Year><Month>10</Month><Day>08</Day></ArticleDate></Article><MedlineJournalInfo><Country>England</Country><MedlineTA>BMC Bioinformatics</MedlineTA><NlmUniqueID>100965194</NlmUniqueID><ISSNLinking>1471-2105</ISSNLinking></MedlineJournalInfo><ChemicalList><Chemical><RegistryNumber>0</RegistryNumber><NameOfSubstance UI=\"D011506\">Proteins</NameOfSubstance></Chemical></ChemicalList><CitationSubset>IM</CitationSubset><MeshHeadingList><MeshHeading><DescriptorName UI=\"D000595\" MajorTopicYN=\"N\">Amino Acid Sequence</DescriptorName></MeshHeading><MeshHeading><DescriptorName UI=\"D019295\" MajorTopicYN=\"N\">Computational Biology</DescriptorName><QualifierName UI=\"Q000379\" MajorTopicYN=\"Y\">methods</QualifierName></MeshHeading><MeshHeading><DescriptorName UI=\"D030562\" MajorTopicYN=\"N\">Databases, Protein</DescriptorName></MeshHeading><MeshHeading><DescriptorName UI=\"D008969\" MajorTopicYN=\"N\">Molecular Sequence Data</DescriptorName></MeshHeading><MeshHeading><DescriptorName UI=\"D017434\" MajorTopicYN=\"Y\">Protein Structure, Tertiary</DescriptorName></MeshHeading><MeshHeading><DescriptorName UI=\"D011506\" MajorTopicYN=\"N\">Proteins</DescriptorName><QualifierName UI=\"Q000737\" MajorTopicYN=\"N\">chemistry</QualifierName></MeshHeading><MeshHeading><DescriptorName UI=\"D016415\" MajorTopicYN=\"Y\">Sequence Alignment</DescriptorName></MeshHeading><MeshHeading><DescriptorName UI=\"D020539\" MajorTopicYN=\"N\">Sequence Analysis, Protein</DescriptorName><QualifierName UI=\"Q000379\" MajorTopicYN=\"Y\">methods</QualifierName></MeshHeading></MeshHeadingList></MedlineCitation><PubmedData><History><PubMedPubDate PubStatus=\"entrez\"><Year>2009</Year><Month>10</Month><Day>9</Day><Hour>6</Hour><Minute>0</Minute></PubMedPubDate><PubMedPubDate PubStatus=\"pubmed\"><Year>2009</Year><Month>10</Month><Day>14</Day><Hour>6</Hour><Minute>0</Minute></PubMedPubDate><PubMedPubDate PubStatus=\"medline\"><Year>2010</Year><Month>2</Month><Day>13</Day><Hour>6</Hour><Minute>0</Minute></PubMedPubDate><PubMedPubDate PubStatus=\"pmc-release\"><Year>2009</Year><Month>10</Month><Day>8</Day></PubMedPubDate></History><PublicationStatus>epublish</PublicationStatus><ArticleIdList><ArticleId IdType=\"pubmed\">19811691</ArticleId><ArticleId IdType=\"pmc\">PMC3226196</ArticleId><ArticleId IdType=\"doi\">10.1186/1471-2105-10-S11-S7</ArticleId><ArticleId IdType=\"pii\">1471-2105-10-S11-S7</ArticleId></ArticleIdList><ReferenceList><Reference><Citation>Larkin M, Blackshields G, Brown N, Chenna R, McGettigan P, McWilliam H, Valentin F, Wallace I, Wilm A, Lopez R, Thompson J, Gibson T, Higgins D. ClustalW and ClustalX version 2. Bioinformatics. 2007;23(21):2947&#x2013;2948. doi: 10.1093/bioinformatics/btm404.</Citation><ArticleIdList><ArticleId IdType=\"doi\">10.1093/bioinformatics/btm404</ArticleId><ArticleId IdType=\"pubmed\">17846036</ArticleId></ArticleIdList></Reference><Reference><Citation>A Conserved Domain Database and Search Service. http://www.ncbi.nlm.nih.gov/Structure/cdd/cdd.shtml</Citation></Reference><Reference><Citation>Marchler-Bauer A, Anderson J, Cherukuri P, DeWeese-Scott C, Geer L, Gwadz M, He S, Hurwitz D, Jackson J, Ke Z, Lanczycki C, Liebert C, Liu C, Lu F, Marchler G, Mullokandov M, Shoemaker B, Simonyan V, Song J, Thiessen P, Yamashita R, Yin J, Zhang D, Bryant S. CDD: A Conserved Domain Database for protein classification. Nucleic Acids Research. 2005. pp. D192&#x2013;D196.</Citation><ArticleIdList><ArticleId IdType=\"pmc\">PMC540023</ArticleId><ArticleId IdType=\"pubmed\">15608175</ArticleId></ArticleIdList></Reference><Reference><Citation>Lungu M, Xu K.  In: Human-Centered Visualization Environments, Volume 4417 of Lecture Notes in Computer Science. Kerren A, Ebert A, Meyer J, editor. Springer; 2006. Biomedical Information Visualization; pp. 311&#x2013;342.http://dx.doi.org/10.1007/978-3-540-71949-6_8</Citation><ArticleIdList><ArticleId IdType=\"doi\">10.1007/978-3-540-71949-6_8</ArticleId></ArticleIdList></Reference><Reference><Citation>Schneider TD, Stephens RM. Sequence Logos: A New Way to Display Consensus Sequences. Nucleic Acids Research. 1990;18:6097&#x2013;6100. doi: 10.1093/nar/18.20.6097.</Citation><ArticleIdList><ArticleId IdType=\"doi\">10.1093/nar/18.20.6097</ArticleId><ArticleId IdType=\"pmc\">PMC332411</ArticleId><ArticleId IdType=\"pubmed\">2172928</ArticleId></ArticleIdList></Reference><Reference><Citation>Slack J, Hildebrand K, Munzner T, John KS. In: Proceedings of the German Conference on Bioinformatics. Giegerich R, Stoye J, editor. Vol. 53. 2004. SequenceJuxtaposer: Fluid Navigation For Large-Scale Sequence Comparison in Context; pp. 37&#x2013;42.</Citation></Reference><Reference><Citation>Mayor C, Brudno M, Schwartz JR, Poliakov A, Rubin EM, Frazer KA, Pachter LS, Dubchak I. VISTA: Visualizing Global DNA Sequence Alignments of Arbitrary Length. Bioinformatics. 2000;16(11):1046&#x2013;1047. doi: 10.1093/bioinformatics/16.11.1046.</Citation><ArticleIdList><ArticleId IdType=\"doi\">10.1093/bioinformatics/16.11.1046</ArticleId><ArticleId IdType=\"pubmed\">11159318</ArticleId></ArticleIdList></Reference><Reference><Citation>Shah N, Couronne O, Pennacchio LA, Brudno M, Batzoglou S, Bethel EW, Rubin EM, Hamann B, Dubchak I. Phylo-VISTA: Interactive visualization of multiple DNA sequence alignments. Bioinformatics. 2004;20(5):636&#x2013;643. doi: 10.1093/bioinformatics/btg459.</Citation><ArticleIdList><ArticleId IdType=\"doi\">10.1093/bioinformatics/btg459</ArticleId><ArticleId IdType=\"pubmed\">15033870</ArticleId></ArticleIdList></Reference><Reference><Citation>Spell R, Brady R, Dietrich F. BARD: A visualization tool for biological sequence analysis. IEEE Symposium on Information Visualization 2003. 2003. pp. 219&#x2013;225.</Citation></Reference><Reference><Citation>InterPro. http://www.ebi.ac.uk/interpro/</Citation></Reference><Reference><Citation>Hunter S, Apweiler R, Attwood TK, Bairoch A, Bateman A, Binns D, Bork P, Das U, Daugherty L, Duquenne L, Finn RD, Gough J, Haft D, Hulo N, Kahn D, Kelly E, Laugraud A, Letunic I, Lonsdale D, Lopez R, Madera M, Maslen J, McAnulla C, McDowall J, Mistry J, Mitchell A, Mulder N, Natale D, Orengo C, Quinn AF, Selengut JD, Sigrist CJA, Thimma M, Thomas PD, Valentin F, Wilson D, Wu CH, Yeats C. InterPro: The integrative protein signature database. Nucleic Acids Research. 2009. pp. D211&#x2013;D215.</Citation><ArticleIdList><ArticleId IdType=\"doi\">10.1093/nar/gkn785</ArticleId><ArticleId IdType=\"pmc\">PMC2686546</ArticleId><ArticleId IdType=\"pubmed\">18940856</ArticleId></ArticleIdList></Reference><Reference><Citation>Consortium TU. The Universal Protein Resource (UniProt) Nucleic Acids Research. 2008. pp. D190&#x2013;D195.</Citation><ArticleIdList><ArticleId IdType=\"pmc\">PMC2238893</ArticleId><ArticleId IdType=\"pubmed\">18045787</ArticleId></ArticleIdList></Reference><Reference><Citation>UniProt. http://www.uniprot.org/</Citation></Reference><Reference><Citation>Clamp M, Cuff J, Searle S, Barton G. The Jalview Java alignment editor. Bioinformatics. 2004;20(3):426&#x2013;427. doi: 10.1093/bioinformatics/btg430.</Citation><ArticleIdList><ArticleId IdType=\"doi\">10.1093/bioinformatics/btg430</ArticleId><ArticleId IdType=\"pubmed\">14960472</ArticleId></ArticleIdList></Reference><Reference><Citation>Felsensein J. PHYLIP. http://evolution.genetics.washington.edu/phylip.html</Citation></Reference><Reference><Citation>Henikoff S, Henikoff JG. Amino acid substitution matrices from protein blocks. Proc Natl Acad Sci USA. 1992;89(22):10915&#x2013;10919. doi: 10.1073/pnas.89.22.10915.</Citation><ArticleIdList><ArticleId IdType=\"doi\">10.1073/pnas.89.22.10915</ArticleId><ArticleId IdType=\"pmc\">PMC50453</ArticleId><ArticleId IdType=\"pubmed\">1438297</ArticleId></ArticleIdList></Reference><Reference><Citation>McLaren K. The development of the CIE 1976 (L*a*b*) uniform colour-space and colour-difference formula. Journal of the Society of Dyers and Colourists. 1976;92:338&#x2013;341.</Citation></Reference><Reference><Citation>Ware C. Information Visualization: Perception for Design. 2. Morgan Kaufmann; 2004.</Citation></Reference><Reference><Citation>Pirolli P, Card SK. Information Foraging. Psychological Review. 1999;4:643&#x2013;674. doi: 10.1037/0033-295X.106.4.643.</Citation><ArticleIdList><ArticleId IdType=\"doi\">10.1037/0033-295X.106.4.643</ArticleId></ArticleIdList></Reference><Reference><Citation>Cock P, Antao T, Chang J, Chapman B, Cox C, Dalke A, Friedberg I, Hamelryck T, Kauff F, Wilczynski B, de Hoon M. Biopython: Freely available Python tools for computational molecular biology and bioinformatics. Bioinformatics. 2009;25(11):1422&#x2013;1423. doi: 10.1093/bioinformatics/btp163.</Citation><ArticleIdList><ArticleId IdType=\"doi\">10.1093/bioinformatics/btp163</ArticleId><ArticleId IdType=\"pmc\">PMC2682512</ArticleId><ArticleId IdType=\"pubmed\">19304878</ArticleId></ArticleIdList></Reference><Reference><Citation>PyOpenGL. http://pyopengl.sourceforge.net/</Citation></Reference><Reference><Citation>wxPython. http://wxpython.org/</Citation></Reference><Reference><Citation>McCarthy F, Wang N, Magee G, Nanduri B, Lawrence M, Camon E, Burrell D, Hill D, Dolan M, Williams W, Luthe D, Bridges S, Burgess S. AgBase: A Functional Genomics Resource for Agriculture. BMC Genomics. 2006;7(229)</Citation><ArticleIdList><ArticleId IdType=\"pmc\">PMC1618847</ArticleId><ArticleId IdType=\"pubmed\">16961921</ArticleId></ArticleIdList></Reference><Reference><Citation>MSAVis. http://agbase.msstate.edu/tools/MSAVis.html</Citation></Reference><Reference><Citation>Bailey TL, Boden M, Buske FA, Frith M, Grant CE, Clementi L, Ren J, Li WW, Noble WS. MEME SUITE: Tools for motif discovery and searching. Nucleic Acids Research. 2009. http://dx.doi.org/10.1093/nar/gkp335</Citation><ArticleIdList><ArticleId IdType=\"doi\">10.1093/nar/gkp335</ArticleId><ArticleId IdType=\"pmc\">PMC2703892</ArticleId><ArticleId IdType=\"pubmed\">19458158</ArticleId></ArticleIdList></Reference><Reference><Citation>The MEME Suite. http://meme.nbcr.net/</Citation></Reference><Reference><Citation>Nicholas KB, Nicholas HB, Deerfield DW. GeneDoc: Analysis and visualization of genetic variation. EMBNEW NEWS. 1997;4:14.</Citation></Reference><Reference><Citation>GeneDoc. http://www.nrbsc.org/gfx/genedoc/</Citation></Reference><Reference><Citation>Hall T. BioEdit Sequence Alignment Editor. http://www.mbio.ncsu.edu/BioEdit/bioedit.html</Citation></Reference></ReferenceList></PubmedData></PubmedArticle></PubmedArticleSet>'\n"
     ]
    }
   ],
   "source": [
    "handle = Entrez.efetch(db=\"pubmed\", id=\"19811691\")\n",
    "print(handle.read())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2. Nucleotide"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1677537253', '1677531637', '1677530470', '1677498759', '1677486604', '2820736972', '2820736955', '2820736938', '2820736920', '2820736903']"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "handle = Entrez.esearch(db=\"nucleotide\", retmax=10, term=\"Severe acute respiratory syndrome\")\n",
    "record = Entrez.read(handle)\n",
    "record[\"IdList\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOCUS       NM_001025366            3660 bp    mRNA    linear   PRI 12-OCT-2024\n",
      "DEFINITION  Homo sapiens vascular endothelial growth factor A (VEGFA),\n",
      "            transcript variant 1, mRNA.\n",
      "ACCESSION   NM_001025366\n",
      "VERSION     NM_001025366.3\n",
      "KEYWORDS    RefSeq.\n",
      "SOURCE      Homo sapiens (human)\n",
      "  ORGANISM  Homo sapiens\n",
      "            Eukaryota; Metazoa; Chordata; Craniata; Vertebrata; Euteleostomi;\n",
      "            Mammalia; Eutheria; Euarchontoglires; Primates; Haplorrhini;\n",
      "            Catarrhini; Hominidae; Homo.\n",
      "REFERENCE   1  (bases 1 to 3660)\n",
      "  AUTHORS   Gutierrez-Zepeda,B.M., Gomez-Del Toro,M.M., Ortiz-Soto,D.J.,\n",
      "            Becerra-Loaiza,D.S., Quiroz-Bolanos,A.F., Topete,A.,\n",
      "            Franco-Topete,R.A., Daneri-Navarro,A., Del Toro-Arreola,A. and\n",
      "            Quintero-Ramos,A.\n",
      "  TITLE     The VEGFA rs3025039 Variant Is a Risk Factor for Breast Cancer in\n",
      "            Mexican Women\n",
      "  JOURNAL   Int J Mol Sci 25 (18), 10172 (2024)\n",
      "   PUBMED   39337657\n",
      "  REMARK    GeneRIF: The VEGFA rs3025039 Variant Is a Risk Factor for Breast\n",
      "            Cancer in Mexican Women.\n",
      "            Publication Status: Online-Only\n",
      "REFERENCE   2  (bases 1 to 3660)\n",
      "  AUTHORS   Eswarappa,S.M., Potdar,A.A., Koch,W.J., Fan,Y., Vasu,K.,\n",
      "            Lindner,D., Willard,B., Graham,L.M., DiCorleto,P.E. and Fox,P.L.\n",
      "  TITLE     Programmed translational readthrough generates antiangiogenic\n",
      "            VEGF-Ax\n",
      "  JOURNAL   Cell 157 (7), 1605-1618 (2014)\n",
      "   PUBMED   24949972\n",
      "  REMARK    GeneRIF: Study shows that VEGFA mRNA in mammalian endothelial cells\n",
      "            undergoes programmed translational readthrough (PTR) generating\n",
      "            VEGF-Ax, an isoform containing a unique 22-amino-acid C terminus\n",
      "            extension. VEGF-Ax was detected in tissue slices from human brain,\n",
      "            colon, small intestine, spleen, and pancreas and from serum from\n",
      "            healthy human subjects.\n",
      "REFERENCE   3  (bases 1 to 3660)\n",
      "  AUTHORS   Bastide,A., Karaa,Z., Bornes,S., Hieblot,C., Lacazette,E., Prats,H.\n",
      "            and Touriol,C.\n",
      "  TITLE     An upstream open reading frame within an IRES controls expression\n",
      "            of a specific VEGF-A isoform\n",
      "  JOURNAL   Nucleic Acids Res 36 (7), 2434-2445 (2008)\n",
      "   PUBMED   18304943\n",
      "REFERENCE   4  (bases 1 to 3660)\n",
      "  AUTHORS   Bates,D.O., Cui,T.G., Doughty,J.M., Winkler,M., Sugiono,M.,\n",
      "            Shields,J.D., Peat,D., Gillatt,D. and Harper,S.J.\n",
      "  TITLE     VEGF165b, an inhibitory splice variant of vascular endothelial\n",
      "            growth factor, is down-regulated in renal cell carcinoma\n",
      "  JOURNAL   Cancer Res 62 (14), 4123-4131 (2002)\n",
      "   PUBMED   12124351\n",
      "REFERENCE   5  (bases 1 to 3660)\n",
      "  AUTHORS   Huez,I., Bornes,S., Bresson,D., Creancier,L. and Prats,H.\n",
      "  TITLE     New vascular endothelial growth factor isoform generated by\n",
      "            internal ribosome entry site-driven CUG translation initiation\n",
      "  JOURNAL   Mol Endocrinol 15 (12), 2197-2210 (2001)\n",
      "   PUBMED   11731620\n",
      "  REMARK    GeneRIF: Includes data regarding non-AUG translation initiation\n",
      "            (CUG) of VEGF\n",
      "REFERENCE   6  (bases 1 to 3660)\n",
      "  AUTHORS   Tee,M.K. and Jaffe,R.B.\n",
      "  TITLE     A precursor form of vascular endothelial growth factor arises by\n",
      "            initiation from an upstream in-frame CUG codon\n",
      "  JOURNAL   Biochem J 359 (Pt 1), 219-226 (2001)\n",
      "   PUBMED   11563986\n",
      "  REMARK    GeneRIF: Includes data regarding non-AUG translation initiation\n",
      "            (CUG) of VEGF\n",
      "REFERENCE   7  (bases 1 to 3660)\n",
      "  AUTHORS   Meiron,M., Anunu,R., Scheinman,E.J., Hashmueli,S. and Levi,B.Z.\n",
      "  TITLE     New isoforms of VEGF are translated from alternative initiation CUG\n",
      "            codons located in its 5'UTR\n",
      "  JOURNAL   Biochem Biophys Res Commun 282 (4), 1053-1060 (2001)\n",
      "   PUBMED   11352659\n",
      "  REMARK    GeneRIF: Includes data regarding non-AUG translation initiation\n",
      "            (CUG) of VEGF\n",
      "REFERENCE   8  (bases 1 to 3660)\n",
      "  AUTHORS   Akiri,G., Nahari,D., Finkelstein,Y., Le,S.Y., Elroy-Stein,O. and\n",
      "            Levi,B.Z.\n",
      "  TITLE     Regulation of vascular endothelial growth factor (VEGF) expression\n",
      "            is mediated by internal initiation of translation and alternative\n",
      "            initiation of transcription\n",
      "  JOURNAL   Oncogene 17 (2), 227-236 (1998)\n",
      "   PUBMED   9674707\n",
      "REFERENCE   9  (bases 1 to 3660)\n",
      "  AUTHORS   de Vries,C., Escobedo,J.A., Ueno,H., Houck,K., Ferrara,N. and\n",
      "            Williams,L.T.\n",
      "  TITLE     The fms-like tyrosine kinase, a receptor for vascular endothelial\n",
      "            growth factor\n",
      "  JOURNAL   Science 255 (5047), 989-991 (1992)\n",
      "   PUBMED   1312256\n",
      "REFERENCE   10 (bases 1 to 3660)\n",
      "  AUTHORS   Tischer,E., Mitchell,R., Hartman,T., Silva,M., Gospodarowicz,D.,\n",
      "            Fiddes,J.C. and Abraham,J.A.\n",
      "  TITLE     The human gene for vascular endothelial growth factor. Multiple\n",
      "            protein forms are encoded through alternative exon splicing\n",
      "  JOURNAL   J Biol Chem 266 (18), 11947-11954 (1991)\n",
      "   PUBMED   1711045\n",
      "COMMENT     REVIEWED REFSEQ: This record has been curated by NCBI staff. The\n",
      "            reference sequence was derived from DA237741.1, CN256173.1,\n",
      "            BU153227.1, S85192.1, AF024710.1, BF700556.1 and BM661679.1.\n",
      "            \n",
      "            On Jun 2, 2019 this sequence version replaced NM_001025366.2.\n",
      "            \n",
      "            Summary: This gene is a member of the PDGF/VEGF growth factor\n",
      "            family. It encodes a heparin-binding protein, which exists as a\n",
      "            disulfide-linked homodimer. This growth factor induces\n",
      "            proliferation and migration of vascular endothelial cells, and is\n",
      "            essential for both physiological and pathological angiogenesis.\n",
      "            Disruption of this gene in mice resulted in abnormal embryonic\n",
      "            blood vessel formation. This gene is upregulated in many known\n",
      "            tumors and its expression is correlated with tumor stage and\n",
      "            progression. Elevated levels of this protein are found in patients\n",
      "            with POEMS syndrome, also known as Crow-Fukase syndrome. Allelic\n",
      "            variants of this gene have been associated with microvascular\n",
      "            complications of diabetes 1 (MVCD1) and atherosclerosis.\n",
      "            Alternatively spliced transcript variants encoding different\n",
      "            isoforms have been described. There is also evidence for\n",
      "            alternative translation initiation from upstream non-AUG (CUG)\n",
      "            codons resulting in additional isoforms. A recent study showed that\n",
      "            a C-terminally extended isoform is produced by use of an\n",
      "            alternative in-frame translation termination codon via a stop codon\n",
      "            readthrough mechanism, and that this isoform is antiangiogenic.\n",
      "            Expression of some isoforms derived from the AUG start codon is\n",
      "            regulated by a small upstream open reading frame, which is located\n",
      "            within an internal ribosome entry site. The levels of VEGF are\n",
      "            increased during infection with severe acute respiratory syndrome\n",
      "            coronavirus 2 (SARS-CoV-2), thus promoting inflammation by\n",
      "            facilitating recruitment of inflammatory cells, and by increasing\n",
      "            the level of angiopoietin II (Ang II), one of two products of the\n",
      "            SARS-CoV-2 binding target, angiotensin-converting enzyme 2 (ACE2).\n",
      "            In turn, Ang II facilitates the elevation of VEGF, thus forming a\n",
      "            vicious cycle in the release of inflammatory cytokines. [provided\n",
      "            by RefSeq, Jun 2020].\n",
      "            \n",
      "            CCDS Note: This CCDS representation starts at an upstream non-AUG\n",
      "            (CUG) translation start codon that is supported by conservation\n",
      "            data and experimental evidence, including that in PMIDs:11352659,\n",
      "            11563986 and 11731620. Most of the publicly available long mRNAs at\n",
      "            this locus do not extend far enough 5' to include the CUG start\n",
      "            codon, including S85192.1 which supports this variant. However,\n",
      "            BC058855.1, several unspliced partial transcripts and the\n",
      "            aforementioned publications all support transcription initiation\n",
      "            further upstream. Hence, this CCDS representation includes the\n",
      "            extended 5' CDS. Alternative translation initiation from a\n",
      "            downstream AUG codon (Met-181), which results in a shorter isoform\n",
      "            with a predicted signal peptide, has also been shown for this gene.\n",
      "            The shorter isoform encoded by this variant is represented by CCDS\n",
      "            55010.1.\n",
      "            \n",
      "            Publication Note:  This RefSeq record includes a subset of the\n",
      "            publications that are available for this gene. Please see the Gene\n",
      "            record to access additional publications.\n",
      "            \n",
      "            ##Evidence-Data-START##\n",
      "            Transcript exon combination :: S85192.1 [ECO:0000332]\n",
      "            RNAseq introns              :: single sample supports all introns\n",
      "                                           SAMEA1968540, SAMEA2145240\n",
      "                                           [ECO:0000348]\n",
      "            ##Evidence-Data-END##\n",
      "            \n",
      "            ##RefSeq-Attributes-START##\n",
      "            coronavirus related      :: involved in cytokine storm inflammatory\n",
      "                                        response\n",
      "            non-AUG initiation codon :: PMID: 11352659, 11563986, 11731620\n",
      "            ##RefSeq-Attributes-END##\n",
      "            COMPLETENESS: full length.\n",
      "PRIMARY     REFSEQ_SPAN         PRIMARY_IDENTIFIER PRIMARY_SPAN        COMP\n",
      "            1-189               DA237741.1         29-217\n",
      "            190-636             CN256173.1         166-612\n",
      "            637-1072            BU153227.1         76-511\n",
      "            1073-1742           S85192.1           105-774\n",
      "            1743-2647           AF024710.1         8-912\n",
      "            2648-2654           BF700556.1         171-177\n",
      "            2655-3624           AF024710.1         920-1889\n",
      "            3625-3660           BM661679.1         16-51               c\n",
      "FEATURES             Location/Qualifiers\n",
      "     source          1..3660\n",
      "                     /organism=\"Homo sapiens\"\n",
      "                     /mol_type=\"mRNA\"\n",
      "                     /db_xref=\"taxon:9606\"\n",
      "                     /chromosome=\"6\"\n",
      "                     /map=\"6p21.1\"\n",
      "     gene            1..3660\n",
      "                     /gene=\"VEGFA\"\n",
      "                     /gene_synonym=\"L-VEGF; MVCD1; VEGF; VPF\"\n",
      "                     /note=\"vascular endothelial growth factor A\"\n",
      "                     /db_xref=\"GeneID:7422\"\n",
      "                     /db_xref=\"HGNC:HGNC:12680\"\n",
      "                     /db_xref=\"MIM:192240\"\n",
      "     exon            1..1102\n",
      "                     /gene=\"VEGFA\"\n",
      "                     /gene_synonym=\"L-VEGF; MVCD1; VEGF; VPF\"\n",
      "                     /inference=\"alignment:Splign:2.1.0\"\n",
      "     misc_feature    485..487\n",
      "                     /gene=\"VEGFA\"\n",
      "                     /gene_synonym=\"L-VEGF; MVCD1; VEGF; VPF\"\n",
      "                     /note=\"upstream in-frame stop codon\"\n",
      "     CDS             497..1735\n",
      "                     /gene=\"VEGFA\"\n",
      "                     /gene_synonym=\"L-VEGF; MVCD1; VEGF; VPF\"\n",
      "                     /note=\"isoform a is encoded by transcript variant 1;\n",
      "                     non-AUG (CUG) translation initiation codon; vascular\n",
      "                     endothelial growth factor A165; vascular permeability\n",
      "                     factor; vascular endothelial growth factor A121; vascular\n",
      "                     endothelial growth factor A, long form\"\n",
      "                     /codon_start=1\n",
      "                     /product=\"vascular endothelial growth factor A, long form\n",
      "                     isoform a\"\n",
      "                     /protein_id=\"NP_001020537.2\"\n",
      "                     /db_xref=\"CCDS:CCDS34457.1\"\n",
      "                     /db_xref=\"GeneID:7422\"\n",
      "                     /db_xref=\"HGNC:HGNC:12680\"\n",
      "                     /db_xref=\"MIM:192240\"\n",
      "                     /translation=\"MTDRQTDTAPSPSYHLLPGRRRTVDAAASRGQGPEPAPGGGVEG\n",
      "                     VGARGVALKLFVQLLGCSRFGGAVVRAGEAEPSGAARSASSGREEPQPEEGEEEEEKE\n",
      "                     EERGPQWRLGARKPGSWTGEAAVCADSAPAARAPQALARASGRGGRVARRGAEESGPP\n",
      "                     HSPSRRGSASRAGPGRASETMNFLLSWVHWSLALLLYLHHAKWSQAAPMAEGGGQNHH\n",
      "                     EVVKFMDVYQRSYCHPIETLVDIFQEYPDEIEYIFKPSCVPLMRCGGCCNDEGLECVP\n",
      "                     TEESNITMQIMRIKPHQGQHIGEMSFLQHNKCECRPKKDRARQEKKSVRGKGKGQKRK\n",
      "                     RKKSRYKSWSVYVGARCCLMPWSLPGPHPCGPCSERRKHLFVQDPQTCKCSCKNTDSR\n",
      "                     CKARQLELNERTCRCDKPRR\"\n",
      "     misc_feature    650..652\n",
      "                     /gene=\"VEGFA\"\n",
      "                     /gene_synonym=\"L-VEGF; MVCD1; VEGF; VPF\"\n",
      "                     /note=\"Region: alternative non-AUG (CUG) translation\n",
      "                     initiation site\"\n",
      "     misc_feature    671..673\n",
      "                     /gene=\"VEGFA\"\n",
      "                     /gene_synonym=\"L-VEGF; MVCD1; VEGF; VPF\"\n",
      "                     /note=\"Region: alternative non-AUG (CUG) translation\n",
      "                     initiation site\"\n",
      "     misc_feature    911..913\n",
      "                     /gene=\"VEGFA\"\n",
      "                     /gene_synonym=\"L-VEGF; MVCD1; VEGF; VPF\"\n",
      "                     /note=\"Region: alternative non-AUG (CUG) translation\n",
      "                     initiation site\"\n",
      "     misc_feature    1037..1039\n",
      "                     /gene=\"VEGFA\"\n",
      "                     /gene_synonym=\"L-VEGF; MVCD1; VEGF; VPF\"\n",
      "                     /note=\"start of isoform i precursor; Region: alternative\n",
      "                     AUG translation initiation site\"\n",
      "     misc_feature    630\n",
      "                     /gene=\"VEGFA\"\n",
      "                     /gene_synonym=\"L-VEGF; MVCD1; VEGF; VPF\"\n",
      "                     /note=\"alternative transcription start site\"\n",
      "     exon            1103..1154\n",
      "                     /gene=\"VEGFA\"\n",
      "                     /gene_synonym=\"L-VEGF; MVCD1; VEGF; VPF\"\n",
      "                     /inference=\"alignment:Splign:2.1.0\"\n",
      "     exon            1155..1351\n",
      "                     /gene=\"VEGFA\"\n",
      "                     /gene_synonym=\"L-VEGF; MVCD1; VEGF; VPF\"\n",
      "                     /inference=\"alignment:Splign:2.1.0\"\n",
      "     exon            1352..1428\n",
      "                     /gene=\"VEGFA\"\n",
      "                     /gene_synonym=\"L-VEGF; MVCD1; VEGF; VPF\"\n",
      "                     /inference=\"alignment:Splign:2.1.0\"\n",
      "     exon            1429..1458\n",
      "                     /gene=\"VEGFA\"\n",
      "                     /gene_synonym=\"L-VEGF; MVCD1; VEGF; VPF\"\n",
      "                     /inference=\"alignment:Splign:2.1.0\"\n",
      "     exon            1459..1581\n",
      "                     /gene=\"VEGFA\"\n",
      "                     /gene_synonym=\"L-VEGF; MVCD1; VEGF; VPF\"\n",
      "                     /inference=\"alignment:Splign:2.1.0\"\n",
      "     exon            1582..1713\n",
      "                     /gene=\"VEGFA\"\n",
      "                     /gene_synonym=\"L-VEGF; MVCD1; VEGF; VPF\"\n",
      "                     /inference=\"alignment:Splign:2.1.0\"\n",
      "     exon            1714..3660\n",
      "                     /gene=\"VEGFA\"\n",
      "                     /gene_synonym=\"L-VEGF; MVCD1; VEGF; VPF\"\n",
      "                     /inference=\"alignment:Splign:2.1.0\"\n",
      "     regulatory      3410..3415\n",
      "                     /regulatory_class=\"polyA_signal_sequence\"\n",
      "                     /gene=\"VEGFA\"\n",
      "                     /gene_synonym=\"L-VEGF; MVCD1; VEGF; VPF\"\n",
      "                     /note=\"hexamer: AATAGA\"\n",
      "     polyA_site      3432\n",
      "                     /gene=\"VEGFA\"\n",
      "                     /gene_synonym=\"L-VEGF; MVCD1; VEGF; VPF\"\n",
      "     regulatory      3634..3639\n",
      "                     /regulatory_class=\"polyA_signal_sequence\"\n",
      "                     /gene=\"VEGFA\"\n",
      "                     /gene_synonym=\"L-VEGF; MVCD1; VEGF; VPF\"\n",
      "                     /note=\"hexamer: ATTAAA\"\n",
      "     polyA_site      3660\n",
      "                     /gene=\"VEGFA\"\n",
      "                     /gene_synonym=\"L-VEGF; MVCD1; VEGF; VPF\"\n",
      "                     /note=\"major polyA site\"\n",
      "ORIGIN      \n",
      "        1 gcggaggctt ggggcagccg ggtagctcgg aggtcgtggc gctgggggct agcaccagcg\n",
      "       61 ctctgtcggg aggcgcagcg gttaggtgga ccggtcagcg gactcaccgg ccagggcgct\n",
      "      121 cggtgctgga atttgatatt cattgatccg ggttttatcc ctcttctttt ttcttaaaca\n",
      "      181 ttttttttta aaactgtatt gtttctcgtt ttaatttatt tttgcttgcc attccccact\n",
      "      241 tgaatcgggc cgacggcttg gggagattgc tctacttccc caaatcactg tggattttgg\n",
      "      301 aaaccagcag aaagaggaaa gaggtagcaa gagctccaga gagaagtcga ggaagagaga\n",
      "      361 gacggggtca gagagagcgc gcgggcgtgc gagcagcgaa agcgacaggg gcaaagtgag\n",
      "      421 tgacctgctt ttgggggtga ccgccggagc gcggcgtgag ccctccccct tgggatcccg\n",
      "      481 cagctgacca gtcgcgctga cggacagaca gacagacacc gcccccagcc ccagctacca\n",
      "      541 cctcctcccc ggccggcggc ggacagtgga cgcggcggcg agccgcgggc aggggccgga\n",
      "      601 gcccgcgccc ggaggcgggg tggagggggt cggggctcgc ggcgtcgcac tgaaactttt\n",
      "      661 cgtccaactt ctgggctgtt ctcgcttcgg aggagccgtg gtccgcgcgg gggaagccga\n",
      "      721 gccgagcgga gccgcgagaa gtgctagctc gggccgggag gagccgcagc cggaggaggg\n",
      "      781 ggaggaggaa gaagagaagg aagaggagag ggggccgcag tggcgactcg gcgctcggaa\n",
      "      841 gccgggctca tggacgggtg aggcggcggt gtgcgcagac agtgctccag ccgcgcgcgc\n",
      "      901 tccccaggcc ctggcccggg cctcgggccg gggaggaaga gtagctcgcc gaggcgccga\n",
      "      961 ggagagcggg ccgccccaca gcccgagccg gagagggagc gcgagccgcg ccggccccgg\n",
      "     1021 tcgggcctcc gaaaccatga actttctgct gtcttgggtg cattggagcc ttgccttgct\n",
      "     1081 gctctacctc caccatgcca agtggtccca ggctgcaccc atggcagaag gaggagggca\n",
      "     1141 gaatcatcac gaagtggtga agttcatgga tgtctatcag cgcagctact gccatccaat\n",
      "     1201 cgagaccctg gtggacatct tccaggagta ccctgatgag atcgagtaca tcttcaagcc\n",
      "     1261 atcctgtgtg cccctgatgc gatgcggggg ctgctgcaat gacgagggcc tggagtgtgt\n",
      "     1321 gcccactgag gagtccaaca tcaccatgca gattatgcgg atcaaacctc accaaggcca\n",
      "     1381 gcacatagga gagatgagct tcctacagca caacaaatgt gaatgcagac caaagaaaga\n",
      "     1441 tagagcaaga caagaaaaaa aatcagttcg aggaaaggga aaggggcaaa aacgaaagcg\n",
      "     1501 caagaaatcc cggtataagt cctggagcgt gtacgttggt gcccgctgct gtctaatgcc\n",
      "     1561 ctggagcctc cctggccccc atccctgtgg gccttgctca gagcggagaa agcatttgtt\n",
      "     1621 tgtacaagat ccgcagacgt gtaaatgttc ctgcaaaaac acagactcgc gttgcaaggc\n",
      "     1681 gaggcagctt gagttaaacg aacgtacttg cagatgtgac aagccgaggc ggtgagccgg\n",
      "     1741 gcaggaggaa ggagcctccc tcagggtttc gggaaccaga tctctcacca ggaaagactg\n",
      "     1801 atacagaacg atcgatacag aaaccacgct gccgccacca caccatcacc atcgacagaa\n",
      "     1861 cagtccttaa tccagaaacc tgaaatgaag gaagaggaga ctctgcgcag agcactttgg\n",
      "     1921 gtccggaggg cgagactccg gcggaagcat tcccgggcgg gtgacccagc acggtccctc\n",
      "     1981 ttggaattgg attcgccatt ttatttttct tgctgctaaa tcaccgagcc cggaagatta\n",
      "     2041 gagagtttta tttctgggat tcctgtagac acacccaccc acatacatac atttatatat\n",
      "     2101 atatatatta tatatatata aaaataaata tctctatttt atatatataa aatatatata\n",
      "     2161 ttcttttttt aaattaacag tgctaatgtt attggtgtct tcactggatg tatttgactg\n",
      "     2221 ctgtggactt gagttgggag gggaatgttc ccactcagat cctgacaggg aagaggagga\n",
      "     2281 gatgagagac tctggcatga tctttttttt gtcccacttg gtggggccag ggtcctctcc\n",
      "     2341 cctgcccagg aatgtgcaag gccagggcat gggggcaaat atgacccagt tttgggaaca\n",
      "     2401 ccgacaaacc cagccctggc gctgagcctc tctaccccag gtcagacgga cagaaagaca\n",
      "     2461 gatcacaggt acagggatga ggacaccggc tctgaccagg agtttgggga gcttcaggac\n",
      "     2521 attgctgtgc tttggggatt ccctccacat gctgcacgcg catctcgccc ccaggggcac\n",
      "     2581 tgcctggaag attcaggagc ctgggcggcc ttcgcttact ctcacctgct tctgagttgc\n",
      "     2641 ccaggagacc actggcagat gtcccggcga agagaagaga cacattgttg gaagaagcag\n",
      "     2701 cccatgacag ctccccttcc tgggactcgc cctcatcctc ttcctgctcc ccttcctggg\n",
      "     2761 gtgcagccta aaaggaccta tgtcctcaca ccattgaaac cactagttct gtccccccag\n",
      "     2821 gagacctggt tgtgtgtgtg tgagtggttg accttcctcc atcccctggt ccttcccttc\n",
      "     2881 ccttcccgag gcacagagag acagggcagg atccacgtgc ccattgtgga ggcagagaaa\n",
      "     2941 agagaaagtg ttttatatac ggtacttatt taatatccct ttttaattag aaattaaaac\n",
      "     3001 agttaattta attaaagagt agggtttttt ttcagtattc ttggttaata tttaatttca\n",
      "     3061 actatttatg agatgtatct tttgctctct cttgctctct tatttgtacc ggtttttgta\n",
      "     3121 tataaaattc atgtttccaa tctctctctc cctgatcggt gacagtcact agcttatctt\n",
      "     3181 gaacagatat ttaattttgc taacactcag ctctgccctc cccgatcccc tggctcccca\n",
      "     3241 gcacacattc ctttgaaata aggtttcaat atacatctac atactatata tatatttggc\n",
      "     3301 aacttgtatt tgtgtgtata tatatatata tatgtttatg tatatatgtg attctgataa\n",
      "     3361 aatagacatt gctattctgt tttttatatg taaaaacaaa acaagaaaaa atagagaatt\n",
      "     3421 ctacatacta aatctctctc cttttttaat tttaatattt gttatcattt atttattggt\n",
      "     3481 gctactgttt atccgtaata attgtgggga aaagatatta acatcacgtc tttgtctcta\n",
      "     3541 gtgcagtttt tcgagatatt ccgtagtaca tatttatttt taaacaacga caaagaaata\n",
      "     3601 cagatatatc ttaaaaaaaa aaaagcattt tgtattaaag aatttaattc tgatctcaaa\n",
      "//\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "handle = Entrez.efetch(db=\"nucleotide\", id='1677537253', rettype=\"gb\", retmode=\"text\")\n",
    "print(handle.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "handle = Entrez.esearch(db='nucleotide', term='accD[Gene Name] AND \"E. coli\"[Organism]', retmax=\"20\")\n",
    "result_list = Entrez.read(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['2822569355', '2822496522', '2822472277', '2822472270', '2822415480', '2822413527', '2822413524', '2822413508', '2822398882', '2822398879', '2822398878', '2822398877', '2822398874', '2822398859', '2822398853', '2822265898', '2822247679', '2822025126', '2821912788', '2821911646']\n",
      "\n",
      "\n",
      "287253\n"
     ]
    }
   ],
   "source": [
    "id_list = result_list['IdList']\n",
    "count = result_list['Count']\n",
    "\n",
    "print(id_list)\n",
    "print(\"\\n\")\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "handle.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. PDB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Bio.PDB import PDBParser,PDBList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class PDBList in module Bio.PDB.PDBList:\n",
      "\n",
      "class PDBList(builtins.object)\n",
      " |  PDBList(server='https://files.wwpdb.org', pdb=None, obsolete_pdb=None, verbose=True)\n",
      " |  \n",
      " |  Quick access to the structure lists on the PDB or its mirrors.\n",
      " |  \n",
      " |  This class provides quick access to the structure lists on the\n",
      " |  PDB server or its mirrors. The structure lists contain\n",
      " |  four-letter PDB codes, indicating that structures are\n",
      " |  new, have been modified or are obsolete. The lists are released\n",
      " |  on a weekly basis.\n",
      " |  \n",
      " |  It also provides a function to retrieve PDB files from the server.\n",
      " |  To use it properly, prepare a directory /pdb or the like,\n",
      " |  where PDB files are stored.\n",
      " |  \n",
      " |  All available file formats (PDB, PDBx/mmCif, PDBML, mmtf) are supported.\n",
      " |  Please note that large structures (containing >62 chains\n",
      " |  and/or 99999 ATOM lines) are no longer stored as a single PDB file\n",
      " |  and by default (when PDB format selected) are not downloaded.\n",
      " |  \n",
      " |  Large structures can be downloaded in other formats, including PDBx/mmCif\n",
      " |  or as a .tar file (a collection of PDB-like formatted files for a given\n",
      " |  structure).\n",
      " |  \n",
      " |  If you want to use this module from inside a proxy, add\n",
      " |  the proxy variable to your environment, e.g. in Unix:\n",
      " |  export HTTP_PROXY='http://realproxy.charite.de:888'\n",
      " |  (This can also be added to ~/.bashrc)\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, server='https://files.wwpdb.org', pdb=None, obsolete_pdb=None, verbose=True)\n",
      " |      Initialize the class with the default server or a custom one.\n",
      " |      \n",
      " |      Argument pdb is the local path to use, defaulting to the current\n",
      " |      directory at the moment of initialisation.\n",
      " |  \n",
      " |  download_all_assemblies(self, listfile: Optional[str] = None, file_format: Optional[str] = None, max_num_threads: Optional[int] = None)\n",
      " |      Retrieve all biological assemblies not in the local PDB copy.\n",
      " |      \n",
      " |      :param listfile: File name to which all assembly codes will be written\n",
      " |      \n",
      " |      :param file_format: Format in which to download the entries.\n",
      " |          Available options are \"mmCif\" or \"pdb\". Defaults to \"mmCif\".\n",
      " |      \n",
      " |      :param max_num_threads: The maximum number of threads to use while downloading the assemblies\n",
      " |  \n",
      " |  download_entire_pdb(self, listfile: Optional[str] = None, file_format: Optional[str] = None, max_num_threads: Optional[int] = None)\n",
      " |      Retrieve all PDB entries not present in the local PDB copy.\n",
      " |      \n",
      " |      NOTE: The default download format has changed from PDB to PDBx/mmCif.\n",
      " |      \n",
      " |      :param listfile: Filename to which all PDB codes will be written\n",
      " |      \n",
      " |      :param file_format: File format. Available options:\n",
      " |      \n",
      " |          * \"mmCif\" (default, PDBx/mmCif file),\n",
      " |          * \"pdb\" (format PDB),\n",
      " |          * \"xml\" (PMDML/XML format),\n",
      " |          * \"mmtf\" (highly compressed),\n",
      " |          * \"bundle\" (PDB formatted archive for large structure)\n",
      " |      \n",
      " |      :param max_num_threads: The maximum number of threads to use while downloading PDB entries\n",
      " |  \n",
      " |  download_obsolete_entries(self, listfile: Optional[str] = None, file_format: Optional[str] = None, max_num_threads: Optional[int] = None)\n",
      " |      Retrieve all obsolete PDB entries not present in local obsolete PDB copy.\n",
      " |      \n",
      " |      NOTE: The default download format has changed from PDB to PDBx/mmCif.\n",
      " |      \n",
      " |      :param listfile: Filename to which all PDB codes will be written\n",
      " |      \n",
      " |      :param file_format: File format. Available options:\n",
      " |      \n",
      " |          * \"mmCif\" (default, PDBx/mmCif file),\n",
      " |          * \"pdb\" (PDB format),\n",
      " |          * \"xml\" (PMDML/XML format).\n",
      " |      \n",
      " |      :param max_num_threads: The maximum number of threads to use while downloading PDB entries\n",
      " |  \n",
      " |  download_pdb_files(self, pdb_codes: list[str], obsolete: bool = False, pdir: Optional[str] = None, file_format: Optional[str] = None, overwrite: bool = False, max_num_threads: Optional[int] = None)\n",
      " |      Fetch set of PDB structure files from the PDB server and store them locally.\n",
      " |      \n",
      " |      :param pdb_codes: A list of 4-symbol PDB structure IDs\n",
      " |      \n",
      " |      :param obsolete:\n",
      " |          Has a meaning only for obsolete structures.\n",
      " |          If True, download the obsolete structure to 'obsolete' folder.\n",
      " |          Otherwise, the download won't be performed.\n",
      " |          This option doesn't work for mmtf format as obsolete structures are not available as mmtf.\n",
      " |          (default: ``False``)\n",
      " |      \n",
      " |      :param pdir: Put the file in this directory. By default, create a PDB-style directory tree.\n",
      " |      \n",
      " |      :param file_format: File format. Available options:\n",
      " |      \n",
      " |          * \"mmCif\" (default, PDBx/mmCif file),\n",
      " |          * \"pdb\" (format PDB),\n",
      " |          * \"xml\" (PMDML/XML format),\n",
      " |          * \"mmtf\" (highly compressed),\n",
      " |          * \"bundle\" (PDB formatted archive for large structure).\n",
      " |      \n",
      " |      :param overwrite: If set to true, existing structure files will be overwritten. (default: ``False``)\n",
      " |      \n",
      " |      :param max_num_threads: The maximum number of threads to use when downloading files\n",
      " |  \n",
      " |  get_all_assemblies(self, file_format: str = '') -> list[tuple[str, str]]\n",
      " |      Retrieve the list of PDB entries with an associated bio assembly.\n",
      " |      \n",
      " |      The requested list will be cached to avoid multiple calls to the server.\n",
      " |      \n",
      " |      :param str file_format: A legacy parameter that is left to avoid breaking changes\n",
      " |      :return: the assemblies\n",
      " |      :rtype: list\n",
      " |  \n",
      " |  get_all_entries(self)\n",
      " |      Retrieve the big file containing all the PDB entries and some annotation.\n",
      " |      \n",
      " |      Returns a list of PDB codes in the index file.\n",
      " |  \n",
      " |  get_all_obsolete(self)\n",
      " |      Return a list of all obsolete entries ever in the PDB.\n",
      " |      \n",
      " |      Returns a list of all obsolete pdb codes that have ever been\n",
      " |      in the PDB.\n",
      " |      \n",
      " |      Gets and parses the file from the PDB server in the format\n",
      " |      (the first pdb_code column is the one used). The file looks\n",
      " |      like this::\n",
      " |      \n",
      " |           LIST OF OBSOLETE COORDINATE ENTRIES AND SUCCESSORS\n",
      " |          OBSLTE    31-JUL-94 116L     216L\n",
      " |          ...\n",
      " |          OBSLTE    29-JAN-96 1HFT     2HFT\n",
      " |          OBSLTE    21-SEP-06 1HFV     2J5X\n",
      " |          OBSLTE    21-NOV-03 1HG6\n",
      " |          OBSLTE    18-JUL-84 1HHB     2HHB 3HHB\n",
      " |          OBSLTE    08-NOV-96 1HID     2HID\n",
      " |          OBSLTE    01-APR-97 1HIU     2HIU\n",
      " |          OBSLTE    14-JAN-04 1HKE     1UUZ\n",
      " |          ...\n",
      " |  \n",
      " |  get_recent_changes(self)\n",
      " |      Return three lists of the newest weekly files (added,mod,obsolete).\n",
      " |      \n",
      " |      Reads the directories with changed entries from the PDB server and\n",
      " |      returns a tuple of three URL's to the files of new, modified and\n",
      " |      obsolete entries from the most recent list. The directory with the\n",
      " |      largest numerical name is used.\n",
      " |      Returns None if something goes wrong.\n",
      " |      \n",
      " |      Contents of the data/status dir (20031013 would be used);:\n",
      " |      \n",
      " |          drwxrwxr-x   2 1002     sysadmin     512 Oct  6 18:28 20031006\n",
      " |          drwxrwxr-x   2 1002     sysadmin     512 Oct 14 02:14 20031013\n",
      " |          -rw-r--r--   1 1002     sysadmin    1327 Mar 12  2001 README\n",
      " |  \n",
      " |  get_seqres_file(self, savefile='pdb_seqres.txt')\n",
      " |      Retrieve and save a (big) file containing all the sequences of PDB entries.\n",
      " |  \n",
      " |  retrieve_assembly_file(self, pdb_code, assembly_num, pdir=None, file_format=None, overwrite=False)\n",
      " |      Fetch one or more assembly structures associated with a PDB entry.\n",
      " |      \n",
      " |      Unless noted below, parameters are described in ``retrieve_pdb_file``.\n",
      " |      \n",
      " |      :type  assembly_num: str\n",
      " |      :param assembly_num: assembly number to download.\n",
      " |      \n",
      " |      :rtype : str\n",
      " |      :return: file name of the downloaded assembly file.\n",
      " |  \n",
      " |  retrieve_pdb_file(self, pdb_code, obsolete=False, pdir=None, file_format=None, overwrite=False)\n",
      " |      Fetch PDB structure file from PDB server, and store it locally.\n",
      " |      \n",
      " |      The PDB structure's file name is returned as a single string.\n",
      " |      If obsolete ``==`` True, the file will be saved in a special file tree.\n",
      " |      \n",
      " |      NOTE. The default download format has changed from PDB to PDBx/mmCif\n",
      " |      \n",
      " |      :param pdb_code: 4-symbols structure Id from PDB (e.g. 3J92).\n",
      " |      :type pdb_code: string\n",
      " |      \n",
      " |      :param file_format:\n",
      " |          File format. Available options:\n",
      " |      \n",
      " |          * \"mmCif\" (default, PDBx/mmCif file),\n",
      " |          * \"pdb\" (format PDB),\n",
      " |          * \"xml\" (PDBML/XML format),\n",
      " |          * \"mmtf\" (highly compressed),\n",
      " |          * \"bundle\" (PDB formatted archive for large structure)\n",
      " |      \n",
      " |      :type file_format: string\n",
      " |      \n",
      " |      :param overwrite: if set to True, existing structure files will be overwritten. Default: False\n",
      " |      :type overwrite: bool\n",
      " |      \n",
      " |      :param obsolete:\n",
      " |          Has a meaning only for obsolete structures. If True, download the obsolete structure\n",
      " |          to 'obsolete' folder, otherwise download won't be performed.\n",
      " |          This option doesn't work for mmtf format as obsoleted structures aren't stored in mmtf.\n",
      " |          Also doesn't have meaning when parameter pdir is specified.\n",
      " |          Note: make sure that you are about to download the really obsolete structure.\n",
      " |          Trying to download non-obsolete structure into obsolete folder will not work\n",
      " |          and you face the \"structure doesn't exists\" error.\n",
      " |          Default: False\n",
      " |      \n",
      " |      :type obsolete: bool\n",
      " |      \n",
      " |      :param pdir: put the file in this directory (default: create a PDB-style directory tree)\n",
      " |      :type pdir: string\n",
      " |      \n",
      " |      :return: filename\n",
      " |      :rtype: string\n",
      " |  \n",
      " |  update_pdb(self, file_format=None, with_assemblies=False)\n",
      " |      Update your local copy of the PDB files.\n",
      " |      \n",
      " |      I guess this is the 'most wanted' function from this module.\n",
      " |      It gets the weekly lists of new and modified pdb entries and\n",
      " |      automatically downloads the according PDB files.\n",
      " |      You can call this module as a weekly cron job.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Static methods defined here:\n",
      " |  \n",
      " |  get_status_list(url)\n",
      " |      Retrieve a list of pdb codes in the weekly pdb status file from given URL.\n",
      " |      \n",
      " |      Used by get_recent_changes. Typical contents of the list files parsed\n",
      " |      by this method is now very simply - one PDB name per line.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors defined here:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes defined here:\n",
      " |  \n",
      " |  PDB_REF = '\\n    The Protein Data Bank: a computer-based arc... pp. 53...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#help(PDBList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading PDB structure '7byr'...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'dir/pdb7byr.ent'"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pdbl=PDBList()\n",
    "pdbl.retrieve_pdb_file(\"7BYR\", file_format=\"pdb\", pdir=\"dir\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "parser= PDBParser()\n",
    "structure = parser.get_structure(\"7BYR\", \"dir/pdb7byr.ent\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chainid: A\n",
      "chainid: B\n",
      "chainid: C\n",
      "chainid: H\n",
      "chainid: L\n",
      "chainid: D\n",
      "chainid: E\n",
      "chainid: F\n",
      "chainid: G\n",
      "chainid: I\n",
      "chainid: J\n"
     ]
    }
   ],
   "source": [
    "for chain in structure[0]:\n",
    "    print(f\"chainid: {chain.id}\")"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "resolution = structure.header[\"resolution\"]\n",
    "resolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'sars-cov-2, antigen, rbd, neutralizing antibody, viral protein'"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keywords = structure.header[\"keywords\"]\n",
    "keywords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. EXPASY"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1. PROSITE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Bio import ExPASy\n",
    "from Bio.ExPASy import Prosite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on module Bio.ExPASy.Prosite in Bio.ExPASy:\n",
      "\n",
      "NAME\n",
      "    Bio.ExPASy.Prosite - Parser for the prosite dat file from Prosite at ExPASy.\n",
      "\n",
      "DESCRIPTION\n",
      "    See https://www.expasy.org/prosite/\n",
      "    \n",
      "    Tested with:\n",
      "     - Release 20.43, 10-Feb-2009\n",
      "     - Release 2017_03 of 15-Mar-2017.\n",
      "    \n",
      "    Functions:\n",
      "     - read                  Reads a Prosite file containing one Prosite record\n",
      "     - parse                 Iterates over records in a Prosite file.\n",
      "    \n",
      "    Classes:\n",
      "     - Record                Holds Prosite data.\n",
      "\n",
      "CLASSES\n",
      "    builtins.object\n",
      "        Record\n",
      "    \n",
      "    class Record(builtins.object)\n",
      "     |  Holds information from a Prosite record.\n",
      "     |  \n",
      "     |  Main attributes:\n",
      "     |   - name           ID of the record.  e.g. ADH_ZINC\n",
      "     |   - type           Type of entry.  e.g. PATTERN, MATRIX, or RULE\n",
      "     |   - accession      e.g. PS00387\n",
      "     |   - created        Date the entry was created.  (MMM-YYYY for releases\n",
      "     |     before January 2017, DD-MMM-YYYY since January 2017)\n",
      "     |   - data_update    Date the 'primary' data was last updated.\n",
      "     |   - info_update    Date data other than 'primary' data was last updated.\n",
      "     |   - pdoc           ID of the PROSITE DOCumentation.\n",
      "     |   - description    Free-format description.\n",
      "     |   - pattern        The PROSITE pattern.  See docs.\n",
      "     |   - matrix         List of strings that describes a matrix entry.\n",
      "     |   - rules          List of rule definitions (from RU lines).  (strings)\n",
      "     |   - prorules       List of prorules (from PR lines). (strings)\n",
      "     |  \n",
      "     |  NUMERICAL RESULTS:\n",
      "     |   - nr_sp_release  SwissProt release.\n",
      "     |   - nr_sp_seqs     Number of seqs in that release of Swiss-Prot. (int)\n",
      "     |   - nr_total       Number of hits in Swiss-Prot.  tuple of (hits, seqs)\n",
      "     |   - nr_positive    True positives.  tuple of (hits, seqs)\n",
      "     |   - nr_unknown     Could be positives.  tuple of (hits, seqs)\n",
      "     |   - nr_false_pos   False positives.  tuple of (hits, seqs)\n",
      "     |   - nr_false_neg   False negatives.  (int)\n",
      "     |   - nr_partial     False negatives, because they are fragments. (int)\n",
      "     |  \n",
      "     |  COMMENTS:\n",
      "     |   - cc_taxo_range  Taxonomic range.  See docs for format\n",
      "     |   - cc_max_repeat  Maximum number of repetitions in a protein\n",
      "     |   - cc_site        Interesting site.  list of tuples (pattern pos, desc.)\n",
      "     |   - cc_skip_flag   Can this entry be ignored?\n",
      "     |   - cc_matrix_type\n",
      "     |   - cc_scaling_db\n",
      "     |   - cc_author\n",
      "     |   - cc_ft_key\n",
      "     |   - cc_ft_desc\n",
      "     |   - cc_version     version number (introduced in release 19.0)\n",
      "     |  \n",
      "     |  The following are all lists if tuples (swiss-prot accession, swiss-prot name).\n",
      "     |  \n",
      "     |  DATA BANK REFERENCES:\n",
      "     |   - dr_positive\n",
      "     |   - dr_false_neg\n",
      "     |   - dr_false_pos\n",
      "     |   - dr_potential   Potential hits, but fingerprint region not yet available.\n",
      "     |   - dr_unknown     Could possibly belong\n",
      "     |   - pdb_structs    List of PDB entries.\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self)\n",
      "     |      Initialize the class.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "\n",
      "FUNCTIONS\n",
      "    parse(handle)\n",
      "        Parse Prosite records.\n",
      "        \n",
      "        This function is for parsing Prosite files containing multiple\n",
      "        records.\n",
      "        \n",
      "        Arguments:\n",
      "         - handle   - handle to the file.\n",
      "    \n",
      "    read(handle)\n",
      "        Read one Prosite record.\n",
      "        \n",
      "        This function is for parsing Prosite files containing\n",
      "        exactly one record.\n",
      "        \n",
      "        Arguments:\n",
      "         - handle   - handle to the file.\n",
      "\n",
      "FILE\n",
      "    /opt/conda/lib/python3.10/site-packages/Bio/ExPASy/Prosite.py\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#help(Prosite)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "handle = ExPASy.get_prosite_raw('PS51442')\n",
    "record = Prosite.read(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coronavirus main protease (M-pro) domain profile.\n"
     ]
    }
   ],
   "source": [
    "print(record.description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "print(record.pdb_structs[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N-{P}-[ST]-{P}.\n"
     ]
    }
   ],
   "source": [
    "handle = ExPASy.get_prosite_raw('PS00001')\n",
    "record = Prosite.read(handle)\n",
    "print(record.pattern)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2. ScanProsite"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Bio.ExPASy import ScanProsite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "258"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prot_record = SeqIO.read(\"prot_seq.fasta\", format=\"fasta\")\n",
    "len(prot_record.seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "handle = ScanProsite.scan(seq=prot_record.seq, mirror=\"https://prosite.expasy.org/\")\n",
    "result = ScanProsite.read(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.n_match"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sequence_ac': 'USERSEQ1',\n",
       " 'start': 1,\n",
       " 'stop': 118,\n",
       " 'signature_ac': 'PS51921',\n",
       " 'score': '32.871',\n",
       " 'level': '0'}"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. KEGG"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Bio.KEGG import REST, Enzyme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on package Bio.KEGG.Enzyme in Bio.KEGG:\n",
      "\n",
      "NAME\n",
      "    Bio.KEGG.Enzyme - Code to work with the KEGG Enzyme database.\n",
      "\n",
      "DESCRIPTION\n",
      "    Functions:\n",
      "     - parse - Returns an iterator giving Record objects.\n",
      "    \n",
      "    Classes:\n",
      "     - Record - Holds the information from a KEGG Enzyme record.\n",
      "\n",
      "PACKAGE CONTENTS\n",
      "\n",
      "\n",
      "CLASSES\n",
      "    builtins.object\n",
      "        Record\n",
      "    \n",
      "    class Record(builtins.object)\n",
      "     |  Holds info from a KEGG Enzyme record.\n",
      "     |  \n",
      "     |  Attributes:\n",
      "     |   - entry       The EC number (without the 'EC ').\n",
      "     |   - name        A list of the enzyme names.\n",
      "     |   - classname   A list of the classification terms.\n",
      "     |   - sysname     The systematic name of the enzyme.\n",
      "     |   - reaction    A list of the reaction description strings.\n",
      "     |   - substrate   A list of the substrates.\n",
      "     |   - product     A list of the products.\n",
      "     |   - inhibitor   A list of the inhibitors.\n",
      "     |   - cofactor    A list of the cofactors.\n",
      "     |   - effector    A list of the effectors.\n",
      "     |   - comment     A list of the comment strings.\n",
      "     |   - pathway     A list of 3-tuples: (database, id, pathway)\n",
      "     |   - genes       A list of 2-tuples: (organism, list of gene ids)\n",
      "     |   - disease     A list of 3-tuples: (database, id, disease)\n",
      "     |   - structures  A list of 2-tuples: (database, list of struct ids)\n",
      "     |   - dblinks     A list of 2-tuples: (database, list of db ids)\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self)\n",
      "     |      Initialize a new Record.\n",
      "     |  \n",
      "     |  __str__(self)\n",
      "     |      Return a string representation of this Record.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "\n",
      "FUNCTIONS\n",
      "    parse(handle)\n",
      "        Parse a KEGG Enzyme file, returning Record objects.\n",
      "        \n",
      "        This is an iterator function, typically used in a for loop.  For\n",
      "        example, using one of the example KEGG files in the Biopython\n",
      "        test suite,\n",
      "        \n",
      "        >>> with open(\"KEGG/enzyme.sample\") as handle:\n",
      "        ...     for record in parse(handle):\n",
      "        ...         print(\"%s %s\" % (record.entry, record.name[0]))\n",
      "        ...\n",
      "        1.1.1.1 alcohol dehydrogenase\n",
      "        1.1.1.62 17beta-estradiol 17-dehydrogenase\n",
      "        1.1.1.68 Transferred to 1.5.1.20\n",
      "        1.6.5.3 NADH:ubiquinone reductase (H+-translocating)\n",
      "        1.14.13.28 3,9-dihydroxypterocarpan 6a-monooxygenase\n",
      "        2.4.1.68 glycoprotein 6-alpha-L-fucosyltransferase\n",
      "        3.1.1.6 acetylesterase\n",
      "        2.7.2.1 acetate kinase\n",
      "    \n",
      "    read(handle)\n",
      "        Parse a KEGG Enzyme file with exactly one entry.\n",
      "        \n",
      "        If the handle contains no records, or more than one record,\n",
      "        an exception is raised.  For example:\n",
      "        \n",
      "        >>> with open(\"KEGG/enzyme.new\") as handle:\n",
      "        ...     record = read(handle)\n",
      "        ...     print(\"%s %s\" % (record.entry, record.name[0]))\n",
      "        ...\n",
      "        6.2.1.25 benzoate---CoA ligase\n",
      "\n",
      "DATA\n",
      "    name_wrap = [0, '', (' ', '$', 1, 1), ('-', '$', 1, 1)]\n",
      "    rxn_wrap = [0, '', (' + ', '', 1, 1), (' = ', '', 1, 1), (' ', '$', 1,...\n",
      "\n",
      "FILE\n",
      "    /opt/conda/lib/python3.10/site-packages/Bio/KEGG/Enzyme/__init__.py\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#help(Enzyme)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "297798"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "request = REST.kegg_get(\"ec:5.4.2.2\")\n",
    "open(\"ec_5.4.2.2\",\"w\").write(request.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Isomerases;',\n",
       " 'Intramolecular transferases;',\n",
       " 'Phosphotransferases (phosphomutases)']"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "records = Enzyme.parse(open(\"ec_5.4.2.2\"))\n",
    "record = list(records)[0]\n",
    "record.classname"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('PATH', 'ec00010', 'Glycolysis / Gluconeogenesis'),\n",
       " ('PATH', 'ec00030', 'Pentose phosphate pathway'),\n",
       " ('PATH', 'ec00052', 'Galactose metabolism'),\n",
       " ('PATH', 'ec00230', 'Purine metabolism'),\n",
       " ('PATH', 'ec00500', 'Starch and sucrose metabolism'),\n",
       " ('PATH', 'ec00520', 'Amino sugar and nucleotide sugar metabolism'),\n",
       " ('PATH', 'ec00521', 'Streptomycin biosynthesis'),\n",
       " ('PATH', 'ec01100', 'Metabolic pathways'),\n",
       " ('PATH', 'ec01110', 'Biosynthesis of secondary metabolites'),\n",
       " ('PATH', 'ec01120', 'Microbial metabolism in diverse environments')]"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "record.pathway"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('HSA', ['5236', '55276']),\n",
       " ('PTR', ['456908', '461162']),\n",
       " ('PPS', ['100977295', '100993927']),\n",
       " ('GGO', ['101128874', '101131551']),\n",
       " ('PON', ['100190836', '100438793']),\n",
       " ('PPYG', ['129034752', '129035286']),\n",
       " ('NLE', ['100596081', '100600656']),\n",
       " ('HMH', ['116456694', '116457795']),\n",
       " ('SSYN', ['129458637', '129464875']),\n",
       " ('MCC', ['100424648', '699401'])]"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "record.genes[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['HSA', 'PTR', 'PPS', 'GGO', 'PON', 'PPYG', 'NLE', 'HMH', 'SSYN', 'MCC']\n"
     ]
    }
   ],
   "source": [
    "list_genes = []\n",
    "for x, y in record.genes:\n",
    "    list_genes += x.split(\"\\n\")\n",
    "    \n",
    "print(list_genes[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------------------------------------------"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
